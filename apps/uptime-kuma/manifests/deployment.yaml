apiVersion: apps/v1
kind: Deployment
metadata:
  name: uptime-kuma
  namespace: uptime-kuma
spec:
  replicas: 1
  selector:
    matchLabels:
      app: uptime-kuma
  strategy:  # Add the update strategy here
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1         # Allow 1 extra pod during updates
      maxUnavailable: 0   # Ensure no pods are unavailable
  template:
    metadata:
      labels:
        app: uptime-kuma
    spec:
      serviceAccountName: uptime-kuma-sa
      # DNS override for local access to avoid hairpin NAT issues
      # Note: hostAliases only supports IPv4, so we use dnsConfig to force IPv4
      hostAliases:
        - ip: "192.168.1.233"
          hostnames:
            - "roomiorentals.com"
            - "dev.roomiorentals.com"
            - "staging.roomiorentals.com"
      # Force DNS to use IPv4 by setting single-request option
      dnsConfig:
        options:
          - name: single-request
          - name: ndots
            value: "1"
      containers:
        - name: uptime-kuma
          image: louislam/uptime-kuma:latest
          env:
            # Disable IPv6 to force IPv4 resolution for local monitoring
            - name: NODE_OPTIONS
              value: "--dns-result-order=ipv4first"
          ports:
            - containerPort: 3001
          volumeMounts:
            - name: data
              mountPath: /app/data
          livenessProbe:
            httpGet:
              path: /
              port: 3001
            initialDelaySeconds: 30  # Wait 30 seconds before starting the first check
            periodSeconds: 10        # Check every 10 seconds
          readinessProbe:                     # Add readiness probe
            httpGet:
              path: /
              port: 3001
            initialDelaySeconds: 10
            periodSeconds: 5
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: uptime-kuma-pvc
