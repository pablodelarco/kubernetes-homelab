apiVersion: v1
items:
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "6"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app":"acestream"},"name":"acestream","namespace":"acestream"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"acestream"}},"strategy":{"type":"Recreate"},"template":{"metadata":{"labels":{"app":"acestream"}},"spec":{"containers":[{"args":["--bind-all","--live-buffer","30","--vod-buffer","30"],"env":[{"name":"ALLOW_REMOTE_ACCESS","value":"yes"},{"name":"CACHE_DIR","value":"/root/.ACEStream/cache"},{"name":"LIVE_BUFFER","value":"30"},{"name":"VOD_BUFFER","value":"30"}],"image":"ghcr.io/martinbjeldbak/acestream-http-proxy:latest","livenessProbe":{"httpGet":{"path":"/webui/api/service","port":6878},"initialDelaySeconds":60,"periodSeconds":30,"timeoutSeconds":10},"name":"acestream","ports":[{"containerPort":6878,"name":"http","protocol":"TCP"}],"readinessProbe":{"httpGet":{"path":"/webui/api/service","port":6878},"initialDelaySeconds":30,"periodSeconds":10,"timeoutSeconds":5},"resources":{"limits":{"cpu":"2000m","memory":"2Gi"},"requests":{"cpu":"250m","memory":"512Mi"}},"volumeMounts":[{"mountPath":"/root/.ACEStream","name":"cache"}]}],"securityContext":{"fsGroup":0,"runAsGroup":0,"runAsUser":0},"volumes":[{"name":"cache","persistentVolumeClaim":{"claimName":"acestream"}}]}}}}
    creationTimestamp: "2025-12-01T23:44:52Z"
    generation: 6
    labels:
      app: acestream
    name: acestream
    namespace: acestream
    resourceVersion: "54068230"
    uid: 95de8332-6c11-4de7-b2a1-8164e2634a2b
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: acestream
    strategy:
      type: Recreate
    template:
      metadata:
        labels:
          app: acestream
      spec:
        containers:
        - args:
          - --bind-all
          - --live-buffer
          - "30"
          - --vod-buffer
          - "30"
          env:
          - name: ALLOW_REMOTE_ACCESS
            value: "yes"
          - name: CACHE_DIR
            value: /root/.ACEStream/cache
          - name: LIVE_BUFFER
            value: "30"
          - name: VOD_BUFFER
            value: "30"
          image: ghcr.io/martinbjeldbak/acestream-http-proxy:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /webui/api/service
              port: 6878
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 10
          name: acestream
          ports:
          - containerPort: 6878
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /webui/api/service
              port: 6878
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          resources:
            limits:
              cpu: "2"
              memory: 2Gi
            requests:
              cpu: 250m
              memory: 512Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /root/.ACEStream
            name: cache
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 0
          runAsGroup: 0
          runAsUser: 0
        terminationGracePeriodSeconds: 30
        volumes:
        - name: cache
          persistentVolumeClaim:
            claimName: acestream
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-12-01T23:44:52Z"
      lastUpdateTime: "2025-12-02T08:45:03Z"
      message: ReplicaSet "acestream-5f8779d4b5" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-10T22:41:04Z"
      lastUpdateTime: "2025-12-10T22:41:04Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 6
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app":"acestream-playlist"},"name":"acestream-playlist","namespace":"acestream"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"acestream-playlist"}},"template":{"metadata":{"labels":{"app":"acestream-playlist"}},"spec":{"containers":[{"image":"nginx:alpine","name":"nginx","ports":[{"containerPort":80,"name":"http","protocol":"TCP"}],"resources":{"limits":{"cpu":"100m","memory":"64Mi"},"requests":{"cpu":"10m","memory":"32Mi"}},"volumeMounts":[{"mountPath":"/usr/share/nginx/html","name":"playlists","readOnly":true}]}],"volumes":[{"configMap":{"name":"acestream-playlists"},"name":"playlists"}]}}}}
    creationTimestamp: "2025-12-01T23:44:52Z"
    generation: 1
    labels:
      app: acestream-playlist
    name: acestream-playlist
    namespace: acestream
    resourceVersion: "54064701"
    uid: 86e8c415-c077-4f3c-9898-ff929f3f8beb
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: acestream-playlist
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app: acestream-playlist
      spec:
        containers:
        - image: nginx:alpine
          imagePullPolicy: IfNotPresent
          name: nginx
          ports:
          - containerPort: 80
            name: http
            protocol: TCP
          resources:
            limits:
              cpu: 100m
              memory: 64Mi
            requests:
              cpu: 10m
              memory: 32Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /usr/share/nginx/html
            name: playlists
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: acestream-playlists
          name: playlists
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-12-01T23:44:52Z"
      lastUpdateTime: "2025-12-01T23:44:54Z"
      message: ReplicaSet "acestream-playlist-5575c8c9c" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-10T22:39:13Z"
      lastUpdateTime: "2025-12-10T22:39:13Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "2"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"applicationset-controller","app.kubernetes.io/name":"argocd-applicationset-controller","app.kubernetes.io/part-of":"argocd"},"name":"argocd-applicationset-controller","namespace":"argocd"},"spec":{"selector":{"matchLabels":{"app.kubernetes.io/name":"argocd-applicationset-controller"}},"template":{"metadata":{"labels":{"app.kubernetes.io/name":"argocd-applicationset-controller"}},"spec":{"containers":[{"args":["/usr/local/bin/argocd-applicationset-controller"],"env":[{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_ANNOTATIONS","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.global.preserved.annotations","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_LABELS","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.global.preserved.labels","name":"argocd-cmd-params-cm","optional":true}}},{"name":"NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_LEADER_ELECTION","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.enable.leader.election","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER","valueFrom":{"configMapKeyRef":{"key":"repo.server","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_POLICY","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.policy","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_POLICY_OVERRIDE","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.enable.policy.override","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_DEBUG","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.debug","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_LOGFORMAT","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.log.format","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_LOGLEVEL","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.log.level","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_DRY_RUN","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.dryrun","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_GIT_MODULES_ENABLED","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.enable.git.submodule","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_PROGRESSIVE_SYNCS","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.enable.progressive.syncs","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.enable.new.git.file.globbing","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_PLAINTEXT","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.repo.server.plaintext","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_STRICT_TLS","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.repo.server.strict.tls","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.repo.server.timeout.seconds","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_CONCURRENT_RECONCILIATIONS","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.concurrent.reconciliations.max","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_NAMESPACES","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.namespaces","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.scm.root.ca.path","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.allowed.scm.providers","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.enable.scm.providers","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_WEBHOOK_PARALLELISM_LIMIT","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.webhook.parallelism.limit","name":"argocd-cmd-params-cm","optional":true}}}],"image":"quay.io/argoproj/argocd:v2.13.2","imagePullPolicy":"Always","name":"argocd-applicationset-controller","ports":[{"containerPort":7000,"name":"webhook"},{"containerPort":8080,"name":"metrics"}],"securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["ALL"]},"readOnlyRootFilesystem":true,"runAsNonRoot":true,"seccompProfile":{"type":"RuntimeDefault"}},"volumeMounts":[{"mountPath":"/app/config/ssh","name":"ssh-known-hosts"},{"mountPath":"/app/config/tls","name":"tls-certs"},{"mountPath":"/app/config/gpg/source","name":"gpg-keys"},{"mountPath":"/app/config/gpg/keys","name":"gpg-keyring"},{"mountPath":"/tmp","name":"tmp"},{"mountPath":"/app/config/reposerver/tls","name":"argocd-repo-server-tls"}]}],"serviceAccountName":"argocd-applicationset-controller","volumes":[{"configMap":{"name":"argocd-ssh-known-hosts-cm"},"name":"ssh-known-hosts"},{"configMap":{"name":"argocd-tls-certs-cm"},"name":"tls-certs"},{"configMap":{"name":"argocd-gpg-keys-cm"},"name":"gpg-keys"},{"emptyDir":{},"name":"gpg-keyring"},{"emptyDir":{},"name":"tmp"},{"name":"argocd-repo-server-tls","secret":{"items":[{"key":"tls.crt","path":"tls.crt"},{"key":"tls.key","path":"tls.key"},{"key":"ca.crt","path":"ca.crt"}],"optional":true,"secretName":"argocd-repo-server-tls"}}]}}}}
    creationTimestamp: "2024-12-26T11:18:28Z"
    generation: 2
    labels:
      app.kubernetes.io/component: applicationset-controller
      app.kubernetes.io/name: argocd-applicationset-controller
      app.kubernetes.io/part-of: argocd
    name: argocd-applicationset-controller
    namespace: argocd
    resourceVersion: "47454111"
    uid: 09f30afc-0ba6-4af9-b744-8bcccb301d8b
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/name: argocd-applicationset-controller
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app.kubernetes.io/name: argocd-applicationset-controller
      spec:
        containers:
        - args:
          - /usr/local/bin/argocd-applicationset-controller
          env:
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_ANNOTATIONS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.global.preserved.annotations
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_LABELS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.global.preserved.labels
                name: argocd-cmd-params-cm
                optional: true
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_LEADER_ELECTION
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.leader.election
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER
            valueFrom:
              configMapKeyRef:
                key: repo.server
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_POLICY
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.policy
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_POLICY_OVERRIDE
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.policy.override
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_DEBUG
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.debug
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGFORMAT
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.log.format
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGLEVEL
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.log.level
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_DRY_RUN
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.dryrun
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_GIT_MODULES_ENABLED
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.git.submodule
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_PROGRESSIVE_SYNCS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.progressive.syncs
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.new.git.file.globbing
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_PLAINTEXT
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.repo.server.plaintext
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_STRICT_TLS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.repo.server.strict.tls
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.repo.server.timeout.seconds
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_CONCURRENT_RECONCILIATIONS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.concurrent.reconciliations.max
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_NAMESPACES
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.namespaces
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.scm.root.ca.path
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.allowed.scm.providers
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.scm.providers
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_WEBHOOK_PARALLELISM_LIMIT
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.webhook.parallelism.limit
                name: argocd-cmd-params-cm
                optional: true
          image: quay.io/argoproj/argocd:v2.13.2
          imagePullPolicy: Always
          name: argocd-applicationset-controller
          ports:
          - containerPort: 7000
            name: webhook
            protocol: TCP
          - containerPort: 8080
            name: metrics
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/config/ssh
            name: ssh-known-hosts
          - mountPath: /app/config/tls
            name: tls-certs
          - mountPath: /app/config/gpg/source
            name: gpg-keys
          - mountPath: /app/config/gpg/keys
            name: gpg-keyring
          - mountPath: /tmp
            name: tmp
          - mountPath: /app/config/reposerver/tls
            name: argocd-repo-server-tls
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: argocd-applicationset-controller
        serviceAccountName: argocd-applicationset-controller
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: argocd-ssh-known-hosts-cm
          name: ssh-known-hosts
        - configMap:
            defaultMode: 420
            name: argocd-tls-certs-cm
          name: tls-certs
        - configMap:
            defaultMode: 420
            name: argocd-gpg-keys-cm
          name: gpg-keys
        - emptyDir: {}
          name: gpg-keyring
        - emptyDir: {}
          name: tmp
        - name: argocd-repo-server-tls
          secret:
            defaultMode: 420
            items:
            - key: tls.crt
              path: tls.crt
            - key: tls.key
              path: tls.key
            - key: ca.crt
              path: ca.crt
            optional: true
            secretName: argocd-repo-server-tls
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-12-26T11:18:28Z"
      lastUpdateTime: "2025-11-02T12:45:25Z"
      message: ReplicaSet "argocd-applicationset-controller-96bcf9b67" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-11-17T10:00:51Z"
      lastUpdateTime: "2025-11-17T10:00:51Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 2
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "2"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"dex-server","app.kubernetes.io/name":"argocd-dex-server","app.kubernetes.io/part-of":"argocd"},"name":"argocd-dex-server","namespace":"argocd"},"spec":{"selector":{"matchLabels":{"app.kubernetes.io/name":"argocd-dex-server"}},"template":{"metadata":{"labels":{"app.kubernetes.io/name":"argocd-dex-server"}},"spec":{"affinity":{"podAntiAffinity":{"preferredDuringSchedulingIgnoredDuringExecution":[{"podAffinityTerm":{"labelSelector":{"matchLabels":{"app.kubernetes.io/part-of":"argocd"}},"topologyKey":"kubernetes.io/hostname"},"weight":5}]}},"containers":[{"command":["/shared/argocd-dex","rundex"],"env":[{"name":"ARGOCD_DEX_SERVER_LOGFORMAT","valueFrom":{"configMapKeyRef":{"key":"dexserver.log.format","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_DEX_SERVER_LOGLEVEL","valueFrom":{"configMapKeyRef":{"key":"dexserver.log.level","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_DEX_SERVER_DISABLE_TLS","valueFrom":{"configMapKeyRef":{"key":"dexserver.disable.tls","name":"argocd-cmd-params-cm","optional":true}}}],"image":"ghcr.io/dexidp/dex:v2.41.1","imagePullPolicy":"Always","name":"dex","ports":[{"containerPort":5556},{"containerPort":5557},{"containerPort":5558}],"securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["ALL"]},"readOnlyRootFilesystem":true,"runAsNonRoot":true,"seccompProfile":{"type":"RuntimeDefault"}},"volumeMounts":[{"mountPath":"/shared","name":"static-files"},{"mountPath":"/tmp","name":"dexconfig"},{"mountPath":"/tls","name":"argocd-dex-server-tls"}]}],"initContainers":[{"command":["/bin/cp","-n","/usr/local/bin/argocd","/shared/argocd-dex"],"image":"quay.io/argoproj/argocd:v2.13.2","imagePullPolicy":"Always","name":"copyutil","securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["ALL"]},"readOnlyRootFilesystem":true,"runAsNonRoot":true,"seccompProfile":{"type":"RuntimeDefault"}},"volumeMounts":[{"mountPath":"/shared","name":"static-files"},{"mountPath":"/tmp","name":"dexconfig"}]}],"serviceAccountName":"argocd-dex-server","volumes":[{"emptyDir":{},"name":"static-files"},{"emptyDir":{},"name":"dexconfig"},{"name":"argocd-dex-server-tls","secret":{"items":[{"key":"tls.crt","path":"tls.crt"},{"key":"tls.key","path":"tls.key"},{"key":"ca.crt","path":"ca.crt"}],"optional":true,"secretName":"argocd-dex-server-tls"}}]}}}}
    creationTimestamp: "2024-12-26T11:18:28Z"
    generation: 2
    labels:
      app.kubernetes.io/component: dex-server
      app.kubernetes.io/name: argocd-dex-server
      app.kubernetes.io/part-of: argocd
    name: argocd-dex-server
    namespace: argocd
    resourceVersion: "47454748"
    uid: 84dc2373-aa7a-41ef-95a0-c4fb2815214d
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/name: argocd-dex-server
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app.kubernetes.io/name: argocd-dex-server
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/part-of: argocd
                topologyKey: kubernetes.io/hostname
              weight: 5
        containers:
        - command:
          - /shared/argocd-dex
          - rundex
          env:
          - name: ARGOCD_DEX_SERVER_LOGFORMAT
            valueFrom:
              configMapKeyRef:
                key: dexserver.log.format
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_DEX_SERVER_LOGLEVEL
            valueFrom:
              configMapKeyRef:
                key: dexserver.log.level
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_DEX_SERVER_DISABLE_TLS
            valueFrom:
              configMapKeyRef:
                key: dexserver.disable.tls
                name: argocd-cmd-params-cm
                optional: true
          image: ghcr.io/dexidp/dex:v2.41.1
          imagePullPolicy: Always
          name: dex
          ports:
          - containerPort: 5556
            protocol: TCP
          - containerPort: 5557
            protocol: TCP
          - containerPort: 5558
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /shared
            name: static-files
          - mountPath: /tmp
            name: dexconfig
          - mountPath: /tls
            name: argocd-dex-server-tls
        dnsPolicy: ClusterFirst
        initContainers:
        - command:
          - /bin/cp
          - -n
          - /usr/local/bin/argocd
          - /shared/argocd-dex
          image: quay.io/argoproj/argocd:v2.13.2
          imagePullPolicy: Always
          name: copyutil
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /shared
            name: static-files
          - mountPath: /tmp
            name: dexconfig
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: argocd-dex-server
        serviceAccountName: argocd-dex-server
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        volumes:
        - emptyDir: {}
          name: static-files
        - emptyDir: {}
          name: dexconfig
        - name: argocd-dex-server-tls
          secret:
            defaultMode: 420
            items:
            - key: tls.crt
              path: tls.crt
            - key: tls.key
              path: tls.key
            - key: ca.crt
              path: ca.crt
            optional: true
            secretName: argocd-dex-server-tls
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-12-26T11:18:28Z"
      lastUpdateTime: "2025-11-02T12:45:29Z"
      message: ReplicaSet "argocd-dex-server-57d5595bfd" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-11-17T10:01:00Z"
      lastUpdateTime: "2025-11-17T10:01:00Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 2
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app.kubernetes.io/instance":"argocd-image-updater","app.kubernetes.io/managed-by":"Helm","app.kubernetes.io/name":"argocd-image-updater","app.kubernetes.io/version":"v1.0.1","control-plane":"argocd-image-updater-controller","helm.sh/chart":"argocd-image-updater-1.0.1"},"name":"argocd-image-updater-controller","namespace":"argocd"},"spec":{"replicas":1,"selector":{"matchLabels":{"app.kubernetes.io/instance":"argocd-image-updater","app.kubernetes.io/name":"argocd-image-updater"}},"strategy":{"type":"Recreate"},"template":{"metadata":{"annotations":{"checksum/config":"97c272d6600977682e90eefa780dd5f8c0b2c3ada1d493069e7af0177f26dc30"},"labels":{"app.kubernetes.io/instance":"argocd-image-updater","app.kubernetes.io/name":"argocd-image-updater"}},"spec":{"containers":[{"args":["--metrics-bind-address=:8443","run","--interval=168h"],"command":["/manager"],"env":[{"name":"IMAGE_UPDATER_INTERVAL","valueFrom":{"configMapKeyRef":{"key":"interval","name":"argocd-image-updater-config","optional":true}}},{"name":"IMAGE_UPDATER_LOGLEVEL","valueFrom":{"configMapKeyRef":{"key":"log.level","name":"argocd-image-updater-config","optional":true}}},{"name":"IMAGE_UPDATER_LOGFORMAT","valueFrom":{"configMapKeyRef":{"key":"log.format","name":"argocd-image-updater-config","optional":true}}},{"name":"MAX_CONCURRENT_APPS","valueFrom":{"configMapKeyRef":{"key":"max_concurrent_apps","name":"argocd-image-updater-config","optional":true}}},{"name":"MAX_CONCURRENT_RECONCILES","valueFrom":{"configMapKeyRef":{"key":"max_concurrent_reconciles","name":"aargocd-image-updater-config","optional":true}}},{"name":"GIT_COMMIT_USER","valueFrom":{"configMapKeyRef":{"key":"git.user","name":"argocd-image-updater-config","optional":true}}},{"name":"GIT_COMMIT_EMAIL","valueFrom":{"configMapKeyRef":{"key":"git.email","name":"argocd-image-updater-config","optional":true}}},{"name":"GIT_COMMIT_SIGNING_KEY","valueFrom":{"configMapKeyRef":{"key":"git.commit-signing-key","name":"argocd-image-updater-config","optional":true}}},{"name":"GIT_COMMIT_SIGNING_METHOD","valueFrom":{"configMapKeyRef":{"key":"git.commit-signing-method","name":"argocd-image-updater-config","optional":true}}},{"name":"GIT_COMMIT_SIGN_OFF","valueFrom":{"configMapKeyRef":{"key":"git.commit-sign-off","name":"argocd-image-updater-config","optional":true}}},{"name":"IMAGE_UPDATER_KUBE_EVENTS","valueFrom":{"configMapKeyRef":{"key":"kube.events","name":"argocd-image-updater-config","optional":true}}},{"name":"ENABLE_WEBHOOK","valueFrom":{"configMapKeyRef":{"key":"webhook.enable","name":"argocd-image-updater-config","optional":true}}},{"name":"WEBHOOK_PORT","valueFrom":{"configMapKeyRef":{"key":"webhook.port","name":"argocd-image-updater-config","optional":true}}},{"name":"QUAY_WEBHOOK_SECRET","valueFrom":{"secretKeyRef":{"key":"webhook.quay-secret","name":"argocd-image-updater-secret","optional":true}}},{"name":"DOCKER_WEBHOOK_SECRET","valueFrom":{"secretKeyRef":{"key":"webhook.docker-secret","name":"argocd-image-updater-secret","optional":true}}},{"name":"GHCR_WEBHOOK_SECRET","valueFrom":{"secretKeyRef":{"key":"webhook.ghcr-secret","name":"argocd-image-updater-secret","optional":true}}},{"name":"HARBOR_WEBHOOK_SECRET","valueFrom":{"secretKeyRef":{"key":"webhook.harbor-secret","name":"argocd-image-updater-secret","optional":true}}},{"name":"WEBHOOK_RATELIMIT_ALLOWED","valueFrom":{"configMapKeyRef":{"key":"webhook.ratelimit-allowed","name":"argocd-image-updater-config","optional":true}}}],"image":"quay.io/argoprojlabs/argocd-image-updater:v1.0.1","imagePullPolicy":"Always","livenessProbe":{"httpGet":{"path":"/healthz","port":8081},"initialDelaySeconds":3,"periodSeconds":30},"name":"argocd-image-updater-controller","ports":[{"containerPort":8081,"name":"health","protocol":"TCP"},{"containerPort":8082,"name":"webhook","protocol":"TCP"},{"containerPort":8443,"name":"metrics","protocol":"TCP"}],"readinessProbe":{"httpGet":{"path":"/readyz","port":8081},"initialDelaySeconds":15,"periodSeconds":20},"resources":{"limits":{"cpu":"200m","memory":"256Mi"},"requests":{"cpu":"50m","memory":"128Mi"}},"securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["ALL"]},"readOnlyRootFilesystem":true,"runAsNonRoot":true,"seccompProfile":{"type":"RuntimeDefault"}},"volumeMounts":[{"mountPath":"/app/config","name":"image-updater-conf"},{"mountPath":"/app/config/ssh","name":"ssh-known-hosts"},{"mountPath":"/app/.ssh","name":"ssh-config"},{"mountPath":"/tmp","name":"tmp"},{"mountPath":"/app/ssh-keys/id_rsa","name":"ssh-signing-key","readOnly":true,"subPath":"sshPrivateKey"}]}],"securityContext":{"runAsNonRoot":true},"serviceAccountName":"argocd-image-updater","terminationGracePeriodSeconds":10,"volumes":[{"configMap":{"items":[{"key":"registries.conf","path":"registries.conf"},{"key":"git.commit-message-template","path":"commit.template"}],"name":"argocd-image-updater-config","optional":true},"name":"image-updater-conf"},{"configMap":{"name":"argocd-ssh-known-hosts-cm","optional":true},"name":"ssh-known-hosts"},{"configMap":{"name":"argocd-image-updater-ssh-config","optional":true},"name":"ssh-config"},{"name":"ssh-signing-key","secret":{"optional":true,"secretName":"ssh-git-creds"}},{"emptyDir":{},"name":"tmp"}]}}}}
    creationTimestamp: "2025-12-05T11:53:06Z"
    generation: 1
    labels:
      app.kubernetes.io/instance: argocd-image-updater
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-image-updater
      app.kubernetes.io/version: v1.0.1
      control-plane: argocd-image-updater-controller
      helm.sh/chart: argocd-image-updater-1.0.1
    name: argocd-image-updater-controller
    namespace: argocd
    resourceVersion: "54430791"
    uid: 401589eb-1d2d-4744-bf30-410c87d3b0c6
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: argocd-image-updater
        app.kubernetes.io/name: argocd-image-updater
    strategy:
      type: Recreate
    template:
      metadata:
        annotations:
          checksum/config: 97c272d6600977682e90eefa780dd5f8c0b2c3ada1d493069e7af0177f26dc30
        labels:
          app.kubernetes.io/instance: argocd-image-updater
          app.kubernetes.io/name: argocd-image-updater
      spec:
        containers:
        - args:
          - --metrics-bind-address=:8443
          - run
          - --interval=168h
          command:
          - /manager
          env:
          - name: IMAGE_UPDATER_INTERVAL
            valueFrom:
              configMapKeyRef:
                key: interval
                name: argocd-image-updater-config
                optional: true
          - name: IMAGE_UPDATER_LOGLEVEL
            valueFrom:
              configMapKeyRef:
                key: log.level
                name: argocd-image-updater-config
                optional: true
          - name: IMAGE_UPDATER_LOGFORMAT
            valueFrom:
              configMapKeyRef:
                key: log.format
                name: argocd-image-updater-config
                optional: true
          - name: MAX_CONCURRENT_APPS
            valueFrom:
              configMapKeyRef:
                key: max_concurrent_apps
                name: argocd-image-updater-config
                optional: true
          - name: MAX_CONCURRENT_RECONCILES
            valueFrom:
              configMapKeyRef:
                key: max_concurrent_reconciles
                name: aargocd-image-updater-config
                optional: true
          - name: GIT_COMMIT_USER
            valueFrom:
              configMapKeyRef:
                key: git.user
                name: argocd-image-updater-config
                optional: true
          - name: GIT_COMMIT_EMAIL
            valueFrom:
              configMapKeyRef:
                key: git.email
                name: argocd-image-updater-config
                optional: true
          - name: GIT_COMMIT_SIGNING_KEY
            valueFrom:
              configMapKeyRef:
                key: git.commit-signing-key
                name: argocd-image-updater-config
                optional: true
          - name: GIT_COMMIT_SIGNING_METHOD
            valueFrom:
              configMapKeyRef:
                key: git.commit-signing-method
                name: argocd-image-updater-config
                optional: true
          - name: GIT_COMMIT_SIGN_OFF
            valueFrom:
              configMapKeyRef:
                key: git.commit-sign-off
                name: argocd-image-updater-config
                optional: true
          - name: IMAGE_UPDATER_KUBE_EVENTS
            valueFrom:
              configMapKeyRef:
                key: kube.events
                name: argocd-image-updater-config
                optional: true
          - name: ENABLE_WEBHOOK
            valueFrom:
              configMapKeyRef:
                key: webhook.enable
                name: argocd-image-updater-config
                optional: true
          - name: WEBHOOK_PORT
            valueFrom:
              configMapKeyRef:
                key: webhook.port
                name: argocd-image-updater-config
                optional: true
          - name: QUAY_WEBHOOK_SECRET
            valueFrom:
              secretKeyRef:
                key: webhook.quay-secret
                name: argocd-image-updater-secret
                optional: true
          - name: DOCKER_WEBHOOK_SECRET
            valueFrom:
              secretKeyRef:
                key: webhook.docker-secret
                name: argocd-image-updater-secret
                optional: true
          - name: GHCR_WEBHOOK_SECRET
            valueFrom:
              secretKeyRef:
                key: webhook.ghcr-secret
                name: argocd-image-updater-secret
                optional: true
          - name: HARBOR_WEBHOOK_SECRET
            valueFrom:
              secretKeyRef:
                key: webhook.harbor-secret
                name: argocd-image-updater-secret
                optional: true
          - name: WEBHOOK_RATELIMIT_ALLOWED
            valueFrom:
              configMapKeyRef:
                key: webhook.ratelimit-allowed
                name: argocd-image-updater-config
                optional: true
          image: quay.io/argoprojlabs/argocd-image-updater:v1.0.1
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8081
              scheme: HTTP
            initialDelaySeconds: 3
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 1
          name: argocd-image-updater-controller
          ports:
          - containerPort: 8081
            name: health
            protocol: TCP
          - containerPort: 8082
            name: webhook
            protocol: TCP
          - containerPort: 8443
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: 8081
              scheme: HTTP
            initialDelaySeconds: 15
            periodSeconds: 20
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              cpu: 200m
              memory: 256Mi
            requests:
              cpu: 50m
              memory: 128Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/config
            name: image-updater-conf
          - mountPath: /app/config/ssh
            name: ssh-known-hosts
          - mountPath: /app/.ssh
            name: ssh-config
          - mountPath: /tmp
            name: tmp
          - mountPath: /app/ssh-keys/id_rsa
            name: ssh-signing-key
            readOnly: true
            subPath: sshPrivateKey
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          runAsNonRoot: true
        serviceAccount: argocd-image-updater
        serviceAccountName: argocd-image-updater
        terminationGracePeriodSeconds: 10
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: registries.conf
              path: registries.conf
            - key: git.commit-message-template
              path: commit.template
            name: argocd-image-updater-config
            optional: true
          name: image-updater-conf
        - configMap:
            defaultMode: 420
            name: argocd-ssh-known-hosts-cm
            optional: true
          name: ssh-known-hosts
        - configMap:
            defaultMode: 420
            name: argocd-image-updater-ssh-config
            optional: true
          name: ssh-config
        - name: ssh-signing-key
          secret:
            defaultMode: 420
            optional: true
            secretName: ssh-git-creds
        - emptyDir: {}
          name: tmp
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-12-05T11:53:07Z"
      lastUpdateTime: "2025-12-05T11:53:43Z"
      message: ReplicaSet "argocd-image-updater-controller-bf589fd9d" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-12T05:52:14Z"
      lastUpdateTime: "2025-12-12T05:52:14Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "2"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"redis","app.kubernetes.io/name":"argocd-redis","app.kubernetes.io/part-of":"argocd"},"name":"argocd-redis","namespace":"argocd"},"spec":{"selector":{"matchLabels":{"app.kubernetes.io/name":"argocd-redis"}},"template":{"metadata":{"labels":{"app.kubernetes.io/name":"argocd-redis"}},"spec":{"affinity":{"podAntiAffinity":{"preferredDuringSchedulingIgnoredDuringExecution":[{"podAffinityTerm":{"labelSelector":{"matchLabels":{"app.kubernetes.io/name":"argocd-redis"}},"topologyKey":"kubernetes.io/hostname"},"weight":100},{"podAffinityTerm":{"labelSelector":{"matchLabels":{"app.kubernetes.io/part-of":"argocd"}},"topologyKey":"kubernetes.io/hostname"},"weight":5}]}},"containers":[{"args":["--save","","--appendonly","no","--requirepass $(REDIS_PASSWORD)"],"env":[{"name":"REDIS_PASSWORD","valueFrom":{"secretKeyRef":{"key":"auth","name":"argocd-redis"}}}],"image":"redis:7.0.15-alpine","imagePullPolicy":"Always","name":"redis","ports":[{"containerPort":6379}],"securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["ALL"]},"readOnlyRootFilesystem":true}}],"initContainers":[{"command":["argocd","admin","redis-initial-password"],"image":"quay.io/argoproj/argocd:v2.13.2","imagePullPolicy":"IfNotPresent","name":"secret-init","securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["ALL"]},"readOnlyRootFilesystem":true,"runAsNonRoot":true,"seccompProfile":{"type":"RuntimeDefault"}}}],"securityContext":{"runAsNonRoot":true,"runAsUser":999,"seccompProfile":{"type":"RuntimeDefault"}},"serviceAccountName":"argocd-redis"}}}}
    creationTimestamp: "2024-12-26T11:18:28Z"
    generation: 2
    labels:
      app.kubernetes.io/component: redis
      app.kubernetes.io/name: argocd-redis
      app.kubernetes.io/part-of: argocd
    name: argocd-redis
    namespace: argocd
    resourceVersion: "47454790"
    uid: e52a56f8-d71d-4668-bca6-e15d5994c2e8
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/name: argocd-redis
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app.kubernetes.io/name: argocd-redis
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: argocd-redis
                topologyKey: kubernetes.io/hostname
              weight: 100
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/part-of: argocd
                topologyKey: kubernetes.io/hostname
              weight: 5
        containers:
        - args:
          - --save
          - ""
          - --appendonly
          - "no"
          - --requirepass $(REDIS_PASSWORD)
          env:
          - name: REDIS_PASSWORD
            valueFrom:
              secretKeyRef:
                key: auth
                name: argocd-redis
          image: redis:7.0.15-alpine
          imagePullPolicy: Always
          name: redis
          ports:
          - containerPort: 6379
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        initContainers:
        - command:
          - argocd
          - admin
          - redis-initial-password
          image: quay.io/argoproj/argocd:v2.13.2
          imagePullPolicy: IfNotPresent
          name: secret-init
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          runAsNonRoot: true
          runAsUser: 999
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: argocd-redis
        serviceAccountName: argocd-redis
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-12-26T11:18:28Z"
      lastUpdateTime: "2025-11-02T12:45:30Z"
      message: ReplicaSet "argocd-redis-86cd498645" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-11-17T10:01:01Z"
      lastUpdateTime: "2025-11-17T10:01:01Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 2
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "7"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"repo-server","app.kubernetes.io/name":"argocd-repo-server","app.kubernetes.io/part-of":"argocd"},"name":"argocd-repo-server","namespace":"argocd"},"spec":{"selector":{"matchLabels":{"app.kubernetes.io/name":"argocd-repo-server"}},"template":{"metadata":{"labels":{"app.kubernetes.io/name":"argocd-repo-server"}},"spec":{"affinity":{"podAntiAffinity":{"preferredDuringSchedulingIgnoredDuringExecution":[{"podAffinityTerm":{"labelSelector":{"matchLabels":{"app.kubernetes.io/name":"argocd-repo-server"}},"topologyKey":"kubernetes.io/hostname"},"weight":100},{"podAffinityTerm":{"labelSelector":{"matchLabels":{"app.kubernetes.io/part-of":"argocd"}},"topologyKey":"kubernetes.io/hostname"},"weight":5}]}},"automountServiceAccountToken":false,"containers":[{"args":["/usr/local/bin/argocd-repo-server"],"env":[{"name":"REDIS_PASSWORD","valueFrom":{"secretKeyRef":{"key":"auth","name":"argocd-redis"}}},{"name":"ARGOCD_RECONCILIATION_TIMEOUT","valueFrom":{"configMapKeyRef":{"key":"timeout.reconciliation","name":"argocd-cm","optional":true}}},{"name":"ARGOCD_REPO_SERVER_LOGFORMAT","valueFrom":{"configMapKeyRef":{"key":"reposerver.log.format","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_REPO_SERVER_LOGLEVEL","valueFrom":{"configMapKeyRef":{"key":"reposerver.log.level","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_REPO_SERVER_PARALLELISM_LIMIT","valueFrom":{"configMapKeyRef":{"key":"reposerver.parallelism.limit","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_REPO_SERVER_LISTEN_ADDRESS","valueFrom":{"configMapKeyRef":{"key":"reposerver.listen.address","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_REPO_SERVER_LISTEN_METRICS_ADDRESS","valueFrom":{"configMapKeyRef":{"key":"reposerver.metrics.listen.address","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_REPO_SERVER_DISABLE_TLS","valueFrom":{"configMapKeyRef":{"key":"reposerver.disable.tls","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_TLS_MIN_VERSION","valueFrom":{"configMapKeyRef":{"key":"reposerver.tls.minversion","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_TLS_MAX_VERSION","valueFrom":{"configMapKeyRef":{"key":"reposerver.tls.maxversion","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_TLS_CIPHERS","valueFrom":{"configMapKeyRef":{"key":"reposerver.tls.ciphers","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_REPO_CACHE_EXPIRATION","valueFrom":{"configMapKeyRef":{"key":"reposerver.repo.cache.expiration","name":"argocd-cmd-params-cm","optional":true}}},{"name":"REDIS_SERVER","valueFrom":{"configMapKeyRef":{"key":"redis.server","name":"argocd-cmd-params-cm","optional":true}}},{"name":"REDIS_COMPRESSION","valueFrom":{"configMapKeyRef":{"key":"redis.compression","name":"argocd-cmd-params-cm","optional":true}}},{"name":"REDISDB","valueFrom":{"configMapKeyRef":{"key":"redis.db","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_DEFAULT_CACHE_EXPIRATION","valueFrom":{"configMapKeyRef":{"key":"reposerver.default.cache.expiration","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_REPO_SERVER_OTLP_ADDRESS","valueFrom":{"configMapKeyRef":{"key":"otlp.address","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_REPO_SERVER_OTLP_INSECURE","valueFrom":{"configMapKeyRef":{"key":"otlp.insecure","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_REPO_SERVER_OTLP_HEADERS","valueFrom":{"configMapKeyRef":{"key":"otlp.headers","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_REPO_SERVER_MAX_COMBINED_DIRECTORY_MANIFESTS_SIZE","valueFrom":{"configMapKeyRef":{"key":"reposerver.max.combined.directory.manifests.size","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_REPO_SERVER_PLUGIN_TAR_EXCLUSIONS","valueFrom":{"configMapKeyRef":{"key":"reposerver.plugin.tar.exclusions","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_REPO_SERVER_ALLOW_OUT_OF_BOUNDS_SYMLINKS","valueFrom":{"configMapKeyRef":{"key":"reposerver.allow.oob.symlinks","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_TAR_SIZE","valueFrom":{"configMapKeyRef":{"key":"reposerver.streamed.manifest.max.tar.size","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_EXTRACTED_SIZE","valueFrom":{"configMapKeyRef":{"key":"reposerver.streamed.manifest.max.extracted.size","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_REPO_SERVER_HELM_MANIFEST_MAX_EXTRACTED_SIZE","valueFrom":{"configMapKeyRef":{"key":"reposerver.helm.manifest.max.extracted.size","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_REPO_SERVER_DISABLE_HELM_MANIFEST_MAX_EXTRACTED_SIZE","valueFrom":{"configMapKeyRef":{"key":"reposerver.disable.helm.manifest.max.extracted.size","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_REVISION_CACHE_LOCK_TIMEOUT","valueFrom":{"configMapKeyRef":{"key":"reposerver.revision.cache.lock.timeout","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_GIT_MODULES_ENABLED","valueFrom":{"configMapKeyRef":{"key":"reposerver.enable.git.submodule","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_GIT_LS_REMOTE_PARALLELISM_LIMIT","valueFrom":{"configMapKeyRef":{"key":"reposerver.git.lsremote.parallelism.limit","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_GIT_REQUEST_TIMEOUT","valueFrom":{"configMapKeyRef":{"key":"reposerver.git.request.timeout","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_GRPC_MAX_SIZE_MB","valueFrom":{"configMapKeyRef":{"key":"reposerver.grpc.max.size","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_REPO_SERVER_INCLUDE_HIDDEN_DIRECTORIES","valueFrom":{"configMapKeyRef":{"key":"reposerver.include.hidden.directories","name":"argocd-cmd-params-cm","optional":true}}},{"name":"HELM_CACHE_HOME","value":"/helm-working-dir"},{"name":"HELM_CONFIG_HOME","value":"/helm-working-dir"},{"name":"HELM_DATA_HOME","value":"/helm-working-dir"}],"image":"quay.io/argoproj/argocd:v2.13.2","imagePullPolicy":"Always","livenessProbe":{"failureThreshold":3,"httpGet":{"path":"/healthz?full=true","port":8084},"initialDelaySeconds":30,"periodSeconds":30,"timeoutSeconds":5},"name":"argocd-repo-server","ports":[{"containerPort":8081},{"containerPort":8084}],"readinessProbe":{"httpGet":{"path":"/healthz","port":8084},"initialDelaySeconds":5,"periodSeconds":10},"securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["ALL"]},"readOnlyRootFilesystem":true,"runAsNonRoot":true,"seccompProfile":{"type":"RuntimeDefault"}},"volumeMounts":[{"mountPath":"/app/config/ssh","name":"ssh-known-hosts"},{"mountPath":"/app/config/tls","name":"tls-certs"},{"mountPath":"/app/config/gpg/source","name":"gpg-keys"},{"mountPath":"/app/config/gpg/keys","name":"gpg-keyring"},{"mountPath":"/app/config/reposerver/tls","name":"argocd-repo-server-tls"},{"mountPath":"/tmp","name":"tmp"},{"mountPath":"/helm-working-dir","name":"helm-working-dir"},{"mountPath":"/home/argocd/cmp-server/plugins","name":"plugins"}]}],"initContainers":[{"command":["/bin/cp","-n","/usr/local/bin/argocd","/var/run/argocd/argocd-cmp-server"],"image":"quay.io/argoproj/argocd:v2.13.2","name":"copyutil","securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["ALL"]},"readOnlyRootFilesystem":true,"runAsNonRoot":true,"seccompProfile":{"type":"RuntimeDefault"}},"volumeMounts":[{"mountPath":"/var/run/argocd","name":"var-files"}]}],"serviceAccountName":"argocd-repo-server","volumes":[{"configMap":{"name":"argocd-ssh-known-hosts-cm"},"name":"ssh-known-hosts"},{"configMap":{"name":"argocd-tls-certs-cm"},"name":"tls-certs"},{"configMap":{"name":"argocd-gpg-keys-cm"},"name":"gpg-keys"},{"emptyDir":{},"name":"gpg-keyring"},{"emptyDir":{},"name":"tmp"},{"emptyDir":{},"name":"helm-working-dir"},{"name":"argocd-repo-server-tls","secret":{"items":[{"key":"tls.crt","path":"tls.crt"},{"key":"tls.key","path":"tls.key"},{"key":"ca.crt","path":"ca.crt"}],"optional":true,"secretName":"argocd-repo-server-tls"}},{"emptyDir":{},"name":"var-files"},{"emptyDir":{},"name":"plugins"}]}}}}
    creationTimestamp: "2024-12-26T11:18:28Z"
    generation: 7
    labels:
      app.kubernetes.io/component: repo-server
      app.kubernetes.io/name: argocd-repo-server
      app.kubernetes.io/part-of: argocd
    name: argocd-repo-server
    namespace: argocd
    resourceVersion: "52388409"
    uid: c0dac7e8-03c2-4a5d-ac6c-244d44ee044b
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/name: argocd-repo-server
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-05T12:40:56+01:00"
        labels:
          app.kubernetes.io/name: argocd-repo-server
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: argocd-repo-server
                topologyKey: kubernetes.io/hostname
              weight: 100
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/part-of: argocd
                topologyKey: kubernetes.io/hostname
              weight: 5
        automountServiceAccountToken: false
        containers:
        - args:
          - /usr/local/bin/argocd-repo-server
          env:
          - name: REDIS_PASSWORD
            valueFrom:
              secretKeyRef:
                key: auth
                name: argocd-redis
          - name: ARGOCD_RECONCILIATION_TIMEOUT
            valueFrom:
              configMapKeyRef:
                key: timeout.reconciliation
                name: argocd-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_LOGFORMAT
            valueFrom:
              configMapKeyRef:
                key: reposerver.log.format
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_LOGLEVEL
            valueFrom:
              configMapKeyRef:
                key: reposerver.log.level
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT
            valueFrom:
              configMapKeyRef:
                key: reposerver.parallelism.limit
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_LISTEN_ADDRESS
            valueFrom:
              configMapKeyRef:
                key: reposerver.listen.address
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_LISTEN_METRICS_ADDRESS
            valueFrom:
              configMapKeyRef:
                key: reposerver.metrics.listen.address
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_DISABLE_TLS
            valueFrom:
              configMapKeyRef:
                key: reposerver.disable.tls
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_TLS_MIN_VERSION
            valueFrom:
              configMapKeyRef:
                key: reposerver.tls.minversion
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_TLS_MAX_VERSION
            valueFrom:
              configMapKeyRef:
                key: reposerver.tls.maxversion
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_TLS_CIPHERS
            valueFrom:
              configMapKeyRef:
                key: reposerver.tls.ciphers
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: reposerver.repo.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: REDIS_SERVER
            valueFrom:
              configMapKeyRef:
                key: redis.server
                name: argocd-cmd-params-cm
                optional: true
          - name: REDIS_COMPRESSION
            valueFrom:
              configMapKeyRef:
                key: redis.compression
                name: argocd-cmd-params-cm
                optional: true
          - name: REDISDB
            valueFrom:
              configMapKeyRef:
                key: redis.db
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_DEFAULT_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: reposerver.default.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_OTLP_ADDRESS
            valueFrom:
              configMapKeyRef:
                key: otlp.address
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_OTLP_INSECURE
            valueFrom:
              configMapKeyRef:
                key: otlp.insecure
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_OTLP_HEADERS
            valueFrom:
              configMapKeyRef:
                key: otlp.headers
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_MAX_COMBINED_DIRECTORY_MANIFESTS_SIZE
            valueFrom:
              configMapKeyRef:
                key: reposerver.max.combined.directory.manifests.size
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_PLUGIN_TAR_EXCLUSIONS
            valueFrom:
              configMapKeyRef:
                key: reposerver.plugin.tar.exclusions
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_ALLOW_OUT_OF_BOUNDS_SYMLINKS
            valueFrom:
              configMapKeyRef:
                key: reposerver.allow.oob.symlinks
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_TAR_SIZE
            valueFrom:
              configMapKeyRef:
                key: reposerver.streamed.manifest.max.tar.size
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_EXTRACTED_SIZE
            valueFrom:
              configMapKeyRef:
                key: reposerver.streamed.manifest.max.extracted.size
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_HELM_MANIFEST_MAX_EXTRACTED_SIZE
            valueFrom:
              configMapKeyRef:
                key: reposerver.helm.manifest.max.extracted.size
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_DISABLE_HELM_MANIFEST_MAX_EXTRACTED_SIZE
            valueFrom:
              configMapKeyRef:
                key: reposerver.disable.helm.manifest.max.extracted.size
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REVISION_CACHE_LOCK_TIMEOUT
            valueFrom:
              configMapKeyRef:
                key: reposerver.revision.cache.lock.timeout
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_GIT_MODULES_ENABLED
            valueFrom:
              configMapKeyRef:
                key: reposerver.enable.git.submodule
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_GIT_LS_REMOTE_PARALLELISM_LIMIT
            valueFrom:
              configMapKeyRef:
                key: reposerver.git.lsremote.parallelism.limit
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_GIT_REQUEST_TIMEOUT
            valueFrom:
              configMapKeyRef:
                key: reposerver.git.request.timeout
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_GRPC_MAX_SIZE_MB
            valueFrom:
              configMapKeyRef:
                key: reposerver.grpc.max.size
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_INCLUDE_HIDDEN_DIRECTORIES
            valueFrom:
              configMapKeyRef:
                key: reposerver.include.hidden.directories
                name: argocd-cmd-params-cm
                optional: true
          - name: HELM_CACHE_HOME
            value: /helm-working-dir
          - name: HELM_CONFIG_HOME
            value: /helm-working-dir
          - name: HELM_DATA_HOME
            value: /helm-working-dir
          image: quay.io/argoproj/argocd:v2.13.2
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz?full=true
              port: 8084
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 5
          name: argocd-repo-server
          ports:
          - containerPort: 8081
            protocol: TCP
          - containerPort: 8084
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8084
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/config/ssh
            name: ssh-known-hosts
          - mountPath: /app/config/tls
            name: tls-certs
          - mountPath: /app/config/gpg/source
            name: gpg-keys
          - mountPath: /app/config/gpg/keys
            name: gpg-keyring
          - mountPath: /app/config/reposerver/tls
            name: argocd-repo-server-tls
          - mountPath: /tmp
            name: tmp
          - mountPath: /helm-working-dir
            name: helm-working-dir
          - mountPath: /home/argocd/cmp-server/plugins
            name: plugins
        dnsPolicy: ClusterFirst
        initContainers:
        - command:
          - /bin/cp
          - -n
          - /usr/local/bin/argocd
          - /var/run/argocd/argocd-cmp-server
          image: quay.io/argoproj/argocd:v2.13.2
          imagePullPolicy: IfNotPresent
          name: copyutil
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/run/argocd
            name: var-files
        nodeSelector:
          kubernetes.io/hostname: beelink
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: argocd-repo-server
        serviceAccountName: argocd-repo-server
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: argocd-ssh-known-hosts-cm
          name: ssh-known-hosts
        - configMap:
            defaultMode: 420
            name: argocd-tls-certs-cm
          name: tls-certs
        - configMap:
            defaultMode: 420
            name: argocd-gpg-keys-cm
          name: gpg-keys
        - emptyDir: {}
          name: gpg-keyring
        - emptyDir: {}
          name: tmp
        - emptyDir: {}
          name: helm-working-dir
        - name: argocd-repo-server-tls
          secret:
            defaultMode: 420
            items:
            - key: tls.crt
              path: tls.crt
            - key: tls.key
              path: tls.key
            - key: ca.crt
              path: ca.crt
            optional: true
            secretName: argocd-repo-server-tls
        - emptyDir: {}
          name: var-files
        - emptyDir: {}
          name: plugins
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-10-23T08:53:07Z"
      lastUpdateTime: "2025-10-23T08:53:07Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-12-26T11:18:28Z"
      lastUpdateTime: "2025-12-05T11:41:11Z"
      message: ReplicaSet "argocd-repo-server-54678d8d88" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 7
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "9"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"server","app.kubernetes.io/name":"argocd-server","app.kubernetes.io/part-of":"argocd"},"name":"argocd-server","namespace":"argocd"},"spec":{"selector":{"matchLabels":{"app.kubernetes.io/name":"argocd-server"}},"template":{"metadata":{"labels":{"app.kubernetes.io/name":"argocd-server"}},"spec":{"affinity":{"podAntiAffinity":{"preferredDuringSchedulingIgnoredDuringExecution":[{"podAffinityTerm":{"labelSelector":{"matchLabels":{"app.kubernetes.io/name":"argocd-server"}},"topologyKey":"kubernetes.io/hostname"},"weight":100},{"podAffinityTerm":{"labelSelector":{"matchLabels":{"app.kubernetes.io/part-of":"argocd"}},"topologyKey":"kubernetes.io/hostname"},"weight":5}]}},"containers":[{"args":["/usr/local/bin/argocd-server"],"env":[{"name":"REDIS_PASSWORD","valueFrom":{"secretKeyRef":{"key":"auth","name":"argocd-redis"}}},{"name":"ARGOCD_SERVER_INSECURE","valueFrom":{"configMapKeyRef":{"key":"server.insecure","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_BASEHREF","valueFrom":{"configMapKeyRef":{"key":"server.basehref","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_ROOTPATH","valueFrom":{"configMapKeyRef":{"key":"server.rootpath","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_LOGFORMAT","valueFrom":{"configMapKeyRef":{"key":"server.log.format","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_LOG_LEVEL","valueFrom":{"configMapKeyRef":{"key":"server.log.level","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_REPO_SERVER","valueFrom":{"configMapKeyRef":{"key":"repo.server","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_DEX_SERVER","valueFrom":{"configMapKeyRef":{"key":"server.dex.server","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_DISABLE_AUTH","valueFrom":{"configMapKeyRef":{"key":"server.disable.auth","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_ENABLE_GZIP","valueFrom":{"configMapKeyRef":{"key":"server.enable.gzip","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_REPO_SERVER_TIMEOUT_SECONDS","valueFrom":{"configMapKeyRef":{"key":"server.repo.server.timeout.seconds","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_X_FRAME_OPTIONS","valueFrom":{"configMapKeyRef":{"key":"server.x.frame.options","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_CONTENT_SECURITY_POLICY","valueFrom":{"configMapKeyRef":{"key":"server.content.security.policy","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_REPO_SERVER_PLAINTEXT","valueFrom":{"configMapKeyRef":{"key":"server.repo.server.plaintext","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_REPO_SERVER_STRICT_TLS","valueFrom":{"configMapKeyRef":{"key":"server.repo.server.strict.tls","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_DEX_SERVER_PLAINTEXT","valueFrom":{"configMapKeyRef":{"key":"server.dex.server.plaintext","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_DEX_SERVER_STRICT_TLS","valueFrom":{"configMapKeyRef":{"key":"server.dex.server.strict.tls","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_TLS_MIN_VERSION","valueFrom":{"configMapKeyRef":{"key":"server.tls.minversion","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_TLS_MAX_VERSION","valueFrom":{"configMapKeyRef":{"key":"server.tls.maxversion","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_TLS_CIPHERS","valueFrom":{"configMapKeyRef":{"key":"server.tls.ciphers","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_CONNECTION_STATUS_CACHE_EXPIRATION","valueFrom":{"configMapKeyRef":{"key":"server.connection.status.cache.expiration","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_OIDC_CACHE_EXPIRATION","valueFrom":{"configMapKeyRef":{"key":"server.oidc.cache.expiration","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_LOGIN_ATTEMPTS_EXPIRATION","valueFrom":{"configMapKeyRef":{"key":"server.login.attempts.expiration","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_STATIC_ASSETS","valueFrom":{"configMapKeyRef":{"key":"server.staticassets","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APP_STATE_CACHE_EXPIRATION","valueFrom":{"configMapKeyRef":{"key":"server.app.state.cache.expiration","name":"argocd-cmd-params-cm","optional":true}}},{"name":"REDIS_SERVER","valueFrom":{"configMapKeyRef":{"key":"redis.server","name":"argocd-cmd-params-cm","optional":true}}},{"name":"REDIS_COMPRESSION","valueFrom":{"configMapKeyRef":{"key":"redis.compression","name":"argocd-cmd-params-cm","optional":true}}},{"name":"REDISDB","valueFrom":{"configMapKeyRef":{"key":"redis.db","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_DEFAULT_CACHE_EXPIRATION","valueFrom":{"configMapKeyRef":{"key":"server.default.cache.expiration","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_MAX_COOKIE_NUMBER","valueFrom":{"configMapKeyRef":{"key":"server.http.cookie.maxnumber","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_LISTEN_ADDRESS","valueFrom":{"configMapKeyRef":{"key":"server.listen.address","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_METRICS_LISTEN_ADDRESS","valueFrom":{"configMapKeyRef":{"key":"server.metrics.listen.address","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_OTLP_ADDRESS","valueFrom":{"configMapKeyRef":{"key":"otlp.address","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_OTLP_INSECURE","valueFrom":{"configMapKeyRef":{"key":"otlp.insecure","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_OTLP_HEADERS","valueFrom":{"configMapKeyRef":{"key":"otlp.headers","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATION_NAMESPACES","valueFrom":{"configMapKeyRef":{"key":"application.namespaces","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_ENABLE_PROXY_EXTENSION","valueFrom":{"configMapKeyRef":{"key":"server.enable.proxy.extension","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_K8SCLIENT_RETRY_MAX","valueFrom":{"configMapKeyRef":{"key":"server.k8sclient.retry.max","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF","valueFrom":{"configMapKeyRef":{"key":"server.k8sclient.retry.base.backoff","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_API_CONTENT_TYPES","valueFrom":{"configMapKeyRef":{"key":"server.api.content.types","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_SERVER_WEBHOOK_PARALLELISM_LIMIT","valueFrom":{"configMapKeyRef":{"key":"server.webhook.parallelism.limit","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.enable.new.git.file.globbing","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.scm.root.ca.path","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.allowed.scm.providers","name":"argocd-cmd-params-cm","optional":true}}},{"name":"ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS","valueFrom":{"configMapKeyRef":{"key":"applicationsetcontroller.enable.scm.providers","name":"argocd-cmd-params-cm","optional":true}}}],"image":"quay.io/argoproj/argocd:v2.13.2","imagePullPolicy":"Always","livenessProbe":{"httpGet":{"path":"/healthz?full=true","port":8080},"initialDelaySeconds":3,"periodSeconds":30,"timeoutSeconds":5},"name":"argocd-server","ports":[{"containerPort":8080},{"containerPort":8083}],"readinessProbe":{"httpGet":{"path":"/healthz","port":8080},"initialDelaySeconds":3,"periodSeconds":30},"securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["ALL"]},"readOnlyRootFilesystem":true,"runAsNonRoot":true,"seccompProfile":{"type":"RuntimeDefault"}},"volumeMounts":[{"mountPath":"/app/config/ssh","name":"ssh-known-hosts"},{"mountPath":"/app/config/tls","name":"tls-certs"},{"mountPath":"/app/config/server/tls","name":"argocd-repo-server-tls"},{"mountPath":"/app/config/dex/tls","name":"argocd-dex-server-tls"},{"mountPath":"/home/argocd","name":"plugins-home"},{"mountPath":"/tmp","name":"tmp"},{"mountPath":"/home/argocd/params","name":"argocd-cmd-params-cm"}]}],"serviceAccountName":"argocd-server","volumes":[{"emptyDir":{},"name":"plugins-home"},{"emptyDir":{},"name":"tmp"},{"configMap":{"name":"argocd-ssh-known-hosts-cm"},"name":"ssh-known-hosts"},{"configMap":{"name":"argocd-tls-certs-cm"},"name":"tls-certs"},{"name":"argocd-repo-server-tls","secret":{"items":[{"key":"tls.crt","path":"tls.crt"},{"key":"tls.key","path":"tls.key"},{"key":"ca.crt","path":"ca.crt"}],"optional":true,"secretName":"argocd-repo-server-tls"}},{"name":"argocd-dex-server-tls","secret":{"items":[{"key":"tls.crt","path":"tls.crt"},{"key":"ca.crt","path":"ca.crt"}],"optional":true,"secretName":"argocd-dex-server-tls"}},{"configMap":{"items":[{"key":"server.profile.enabled","path":"profiler.enabled"}],"name":"argocd-cmd-params-cm","optional":true},"name":"argocd-cmd-params-cm"}]}}}}
    creationTimestamp: "2024-12-26T11:18:28Z"
    generation: 9
    labels:
      app.kubernetes.io/component: server
      app.kubernetes.io/name: argocd-server
      app.kubernetes.io/part-of: argocd
    name: argocd-server
    namespace: argocd
    resourceVersion: "47454923"
    uid: 47185de4-12ba-4d11-b548-f2c6aa5f807f
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/name: argocd-server
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-01-04T00:06:31+01:00"
        labels:
          app.kubernetes.io/name: argocd-server
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: argocd-server
                topologyKey: kubernetes.io/hostname
              weight: 100
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/part-of: argocd
                topologyKey: kubernetes.io/hostname
              weight: 5
        containers:
        - args:
          - /usr/local/bin/argocd-server
          env:
          - name: REDIS_PASSWORD
            valueFrom:
              secretKeyRef:
                key: auth
                name: argocd-redis
          - name: ARGOCD_SERVER_INSECURE
            valueFrom:
              configMapKeyRef:
                key: server.insecure
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_BASEHREF
            valueFrom:
              configMapKeyRef:
                key: server.basehref
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_ROOTPATH
            valueFrom:
              configMapKeyRef:
                key: server.rootpath
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_LOGFORMAT
            valueFrom:
              configMapKeyRef:
                key: server.log.format
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_LOG_LEVEL
            valueFrom:
              configMapKeyRef:
                key: server.log.level
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_REPO_SERVER
            valueFrom:
              configMapKeyRef:
                key: repo.server
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_DEX_SERVER
            valueFrom:
              configMapKeyRef:
                key: server.dex.server
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_DISABLE_AUTH
            valueFrom:
              configMapKeyRef:
                key: server.disable.auth
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_ENABLE_GZIP
            valueFrom:
              configMapKeyRef:
                key: server.enable.gzip
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_REPO_SERVER_TIMEOUT_SECONDS
            valueFrom:
              configMapKeyRef:
                key: server.repo.server.timeout.seconds
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_X_FRAME_OPTIONS
            valueFrom:
              configMapKeyRef:
                key: server.x.frame.options
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_CONTENT_SECURITY_POLICY
            valueFrom:
              configMapKeyRef:
                key: server.content.security.policy
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_REPO_SERVER_PLAINTEXT
            valueFrom:
              configMapKeyRef:
                key: server.repo.server.plaintext
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_REPO_SERVER_STRICT_TLS
            valueFrom:
              configMapKeyRef:
                key: server.repo.server.strict.tls
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_DEX_SERVER_PLAINTEXT
            valueFrom:
              configMapKeyRef:
                key: server.dex.server.plaintext
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_DEX_SERVER_STRICT_TLS
            valueFrom:
              configMapKeyRef:
                key: server.dex.server.strict.tls
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_TLS_MIN_VERSION
            valueFrom:
              configMapKeyRef:
                key: server.tls.minversion
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_TLS_MAX_VERSION
            valueFrom:
              configMapKeyRef:
                key: server.tls.maxversion
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_TLS_CIPHERS
            valueFrom:
              configMapKeyRef:
                key: server.tls.ciphers
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_CONNECTION_STATUS_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: server.connection.status.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_OIDC_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: server.oidc.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_LOGIN_ATTEMPTS_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: server.login.attempts.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_STATIC_ASSETS
            valueFrom:
              configMapKeyRef:
                key: server.staticassets
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APP_STATE_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: server.app.state.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: REDIS_SERVER
            valueFrom:
              configMapKeyRef:
                key: redis.server
                name: argocd-cmd-params-cm
                optional: true
          - name: REDIS_COMPRESSION
            valueFrom:
              configMapKeyRef:
                key: redis.compression
                name: argocd-cmd-params-cm
                optional: true
          - name: REDISDB
            valueFrom:
              configMapKeyRef:
                key: redis.db
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_DEFAULT_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: server.default.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_MAX_COOKIE_NUMBER
            valueFrom:
              configMapKeyRef:
                key: server.http.cookie.maxnumber
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_LISTEN_ADDRESS
            valueFrom:
              configMapKeyRef:
                key: server.listen.address
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_METRICS_LISTEN_ADDRESS
            valueFrom:
              configMapKeyRef:
                key: server.metrics.listen.address
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_OTLP_ADDRESS
            valueFrom:
              configMapKeyRef:
                key: otlp.address
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_OTLP_INSECURE
            valueFrom:
              configMapKeyRef:
                key: otlp.insecure
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_OTLP_HEADERS
            valueFrom:
              configMapKeyRef:
                key: otlp.headers
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_NAMESPACES
            valueFrom:
              configMapKeyRef:
                key: application.namespaces
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_ENABLE_PROXY_EXTENSION
            valueFrom:
              configMapKeyRef:
                key: server.enable.proxy.extension
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_K8SCLIENT_RETRY_MAX
            valueFrom:
              configMapKeyRef:
                key: server.k8sclient.retry.max
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF
            valueFrom:
              configMapKeyRef:
                key: server.k8sclient.retry.base.backoff
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_API_CONTENT_TYPES
            valueFrom:
              configMapKeyRef:
                key: server.api.content.types
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_WEBHOOK_PARALLELISM_LIMIT
            valueFrom:
              configMapKeyRef:
                key: server.webhook.parallelism.limit
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.new.git.file.globbing
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.scm.root.ca.path
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.allowed.scm.providers
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.scm.providers
                name: argocd-cmd-params-cm
                optional: true
          image: quay.io/argoproj/argocd:v2.13.2
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz?full=true
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 3
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 5
          name: argocd-server
          ports:
          - containerPort: 8080
            protocol: TCP
          - containerPort: 8083
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 3
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/config/ssh
            name: ssh-known-hosts
          - mountPath: /app/config/tls
            name: tls-certs
          - mountPath: /app/config/server/tls
            name: argocd-repo-server-tls
          - mountPath: /app/config/dex/tls
            name: argocd-dex-server-tls
          - mountPath: /home/argocd
            name: plugins-home
          - mountPath: /tmp
            name: tmp
          - mountPath: /home/argocd/params
            name: argocd-cmd-params-cm
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: argocd-server
        serviceAccountName: argocd-server
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        volumes:
        - emptyDir: {}
          name: plugins-home
        - emptyDir: {}
          name: tmp
        - configMap:
            defaultMode: 420
            name: argocd-ssh-known-hosts-cm
          name: ssh-known-hosts
        - configMap:
            defaultMode: 420
            name: argocd-tls-certs-cm
          name: tls-certs
        - name: argocd-repo-server-tls
          secret:
            defaultMode: 420
            items:
            - key: tls.crt
              path: tls.crt
            - key: tls.key
              path: tls.key
            - key: ca.crt
              path: ca.crt
            optional: true
            secretName: argocd-repo-server-tls
        - name: argocd-dex-server-tls
          secret:
            defaultMode: 420
            items:
            - key: tls.crt
              path: tls.crt
            - key: ca.crt
              path: ca.crt
            optional: true
            secretName: argocd-dex-server-tls
        - configMap:
            defaultMode: 420
            items:
            - key: server.profile.enabled
              path: profiler.enabled
            name: argocd-cmd-params-cm
            optional: true
          name: argocd-cmd-params-cm
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-01-03T22:57:33Z"
      lastUpdateTime: "2025-11-02T12:45:26Z"
      message: ReplicaSet "argocd-server-678df9ccdb" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-11-17T10:01:28Z"
      lastUpdateTime: "2025-11-17T10:01:28Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 9
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      cert-manager.clusterctl.cluster.x-k8s.io/version: v1.16.2
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2025-02-06T16:55:54Z"
    generation: 1
    labels:
      app: cert-manager
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: cert-manager
      app.kubernetes.io/name: cert-manager
      app.kubernetes.io/version: v1.16.2
      clusterctl.cluster.x-k8s.io: ""
      clusterctl.cluster.x-k8s.io/core: cert-manager
    name: cert-manager
    namespace: cert-manager
    resourceVersion: "39326477"
    uid: 623a8d21-e299-46b4-95da-8042542e8dfd
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/component: controller
        app.kubernetes.io/instance: cert-manager
        app.kubernetes.io/name: cert-manager
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          prometheus.io/path: /metrics
          prometheus.io/port: "9402"
          prometheus.io/scrape: "true"
        labels:
          app: cert-manager
          app.kubernetes.io/component: controller
          app.kubernetes.io/instance: cert-manager
          app.kubernetes.io/name: cert-manager
          app.kubernetes.io/version: v1.16.2
      spec:
        containers:
        - args:
          - --v=2
          - --cluster-resource-namespace=$(POD_NAMESPACE)
          - --leader-election-namespace=kube-system
          - --acme-http01-solver-image=quay.io/jetstack/cert-manager-acmesolver:v1.16.2
          - --max-concurrent-challenges=60
          env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: quay.io/jetstack/cert-manager-controller:v1.16.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 8
            httpGet:
              path: /livez
              port: http-healthz
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 15
          name: cert-manager-controller
          ports:
          - containerPort: 9402
            name: http-metrics
            protocol: TCP
          - containerPort: 9403
            name: http-healthz
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        enableServiceLinks: false
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: cert-manager
        serviceAccountName: cert-manager
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-02-06T16:55:54Z"
      lastUpdateTime: "2025-02-06T16:56:00Z"
      message: ReplicaSet "cert-manager-74b56b6655" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-10-15T12:57:17Z"
      lastUpdateTime: "2025-10-15T12:57:17Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      cert-manager.clusterctl.cluster.x-k8s.io/version: v1.16.2
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2025-02-06T16:55:54Z"
    generation: 1
    labels:
      app: cainjector
      app.kubernetes.io/component: cainjector
      app.kubernetes.io/instance: cert-manager
      app.kubernetes.io/name: cainjector
      app.kubernetes.io/version: v1.16.2
      clusterctl.cluster.x-k8s.io: ""
      clusterctl.cluster.x-k8s.io/core: cert-manager
    name: cert-manager-cainjector
    namespace: cert-manager
    resourceVersion: "39822214"
    uid: 354edac2-7ea1-4ef1-94f5-587a6501bf48
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/component: cainjector
        app.kubernetes.io/instance: cert-manager
        app.kubernetes.io/name: cainjector
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          prometheus.io/path: /metrics
          prometheus.io/port: "9402"
          prometheus.io/scrape: "true"
        labels:
          app: cainjector
          app.kubernetes.io/component: cainjector
          app.kubernetes.io/instance: cert-manager
          app.kubernetes.io/name: cainjector
          app.kubernetes.io/version: v1.16.2
      spec:
        containers:
        - args:
          - --v=2
          - --leader-election-namespace=kube-system
          env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: quay.io/jetstack/cert-manager-cainjector:v1.16.2
          imagePullPolicy: IfNotPresent
          name: cert-manager-cainjector
          ports:
          - containerPort: 9402
            name: http-metrics
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        enableServiceLinks: false
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: cert-manager-cainjector
        serviceAccountName: cert-manager-cainjector
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-02-06T16:55:54Z"
      lastUpdateTime: "2025-02-06T16:56:02Z"
      message: ReplicaSet "cert-manager-cainjector-55d94dc4cc" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-10-18T12:30:51Z"
      lastUpdateTime: "2025-10-18T12:30:51Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      cert-manager.clusterctl.cluster.x-k8s.io/version: v1.16.2
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2025-02-06T16:55:54Z"
    generation: 1
    labels:
      app: webhook
      app.kubernetes.io/component: webhook
      app.kubernetes.io/instance: cert-manager
      app.kubernetes.io/name: webhook
      app.kubernetes.io/version: v1.16.2
      clusterctl.cluster.x-k8s.io: ""
      clusterctl.cluster.x-k8s.io/core: cert-manager
    name: cert-manager-webhook
    namespace: cert-manager
    resourceVersion: "39821658"
    uid: 99363669-6869-4444-8021-cff04ea7e2d3
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/component: webhook
        app.kubernetes.io/instance: cert-manager
        app.kubernetes.io/name: webhook
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          prometheus.io/path: /metrics
          prometheus.io/port: "9402"
          prometheus.io/scrape: "true"
        labels:
          app: webhook
          app.kubernetes.io/component: webhook
          app.kubernetes.io/instance: cert-manager
          app.kubernetes.io/name: webhook
          app.kubernetes.io/version: v1.16.2
      spec:
        containers:
        - args:
          - --v=2
          - --secure-port=10250
          - --dynamic-serving-ca-secret-namespace=$(POD_NAMESPACE)
          - --dynamic-serving-ca-secret-name=cert-manager-webhook-ca
          - --dynamic-serving-dns-names=cert-manager-webhook
          - --dynamic-serving-dns-names=cert-manager-webhook.$(POD_NAMESPACE)
          - --dynamic-serving-dns-names=cert-manager-webhook.$(POD_NAMESPACE).svc
          env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: quay.io/jetstack/cert-manager-webhook:v1.16.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /livez
              port: 6080
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: cert-manager-webhook
          ports:
          - containerPort: 10250
            name: https
            protocol: TCP
          - containerPort: 6080
            name: healthcheck
            protocol: TCP
          - containerPort: 9402
            name: http-metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 6080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        enableServiceLinks: false
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: cert-manager-webhook
        serviceAccountName: cert-manager-webhook
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-02-06T16:55:54Z"
      lastUpdateTime: "2025-02-06T16:56:09Z"
      message: ReplicaSet "cert-manager-webhook-564f647c66" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-10-18T12:30:38Z"
      lastUpdateTime: "2025-10-18T12:30:38Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2025-08-13T09:56:08Z"
    generation: 1
    labels:
      kind: client
      name: client
    name: client
    namespace: cilium-test-1
    resourceVersion: "39326338"
    uid: 49e027c8-cafd-4a6d-a2ad-7ac5fd6314a5
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        kind: client
        name: client
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          kind: client
          name: client
        name: client
      spec:
        affinity: {}
        containers:
        - command:
          - /usr/bin/pause
          image: quay.io/cilium/alpine-curl:v1.10.0@sha256:913e8c9f3d960dde03882defa0edd3a919d529c2eb167caa7f54194528bde364
          imagePullPolicy: IfNotPresent
          name: client
          resources: {}
          securityContext:
            capabilities:
              add:
              - NET_RAW
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: client
        serviceAccountName: client
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-08-13T15:28:05Z"
      lastUpdateTime: "2025-08-13T15:28:05Z"
      message: ReplicaSet "client-645b68dcf7" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-10-15T12:57:14Z"
      lastUpdateTime: "2025-10-15T12:57:14Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2025-08-13T09:56:08Z"
    generation: 1
    labels:
      kind: client
      name: client2
    name: client2
    namespace: cilium-test-1
    resourceVersion: "39326644"
    uid: 4dab497b-49f6-47a9-9e40-999474f9f112
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        kind: client
        name: client2
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          kind: client
          name: client2
          other: client
        name: client2
      spec:
        affinity:
          podAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                - key: name
                  operator: In
                  values:
                  - client
              topologyKey: kubernetes.io/hostname
        containers:
        - command:
          - /usr/bin/pause
          image: quay.io/cilium/alpine-curl:v1.10.0@sha256:913e8c9f3d960dde03882defa0edd3a919d529c2eb167caa7f54194528bde364
          imagePullPolicy: IfNotPresent
          name: client2
          resources: {}
          securityContext:
            capabilities:
              add:
              - NET_RAW
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: client2
        serviceAccountName: client2
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-08-13T15:28:09Z"
      lastUpdateTime: "2025-08-13T15:28:09Z"
      message: ReplicaSet "client2-66475877c6" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-10-15T12:57:21Z"
      lastUpdateTime: "2025-10-15T12:57:21Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2025-08-13T09:56:08Z"
    generation: 1
    labels:
      kind: echo
      name: echo-same-node
    name: echo-same-node
    namespace: cilium-test-1
    resourceVersion: "39881786"
    uid: c0e68325-55bc-4a83-b93e-0337c711d6da
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        kind: echo
        name: echo-same-node
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          kind: echo
          name: echo-same-node
          other: echo
        name: echo-same-node
      spec:
        affinity:
          podAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                - key: name
                  operator: In
                  values:
                  - client
              topologyKey: kubernetes.io/hostname
        containers:
        - env:
          - name: PORT
            value: "8080"
          - name: NAMED_PORT
            value: http-8080
          image: quay.io/cilium/json-mock:v1.3.8@sha256:5aad04835eda9025fe4561ad31be77fd55309af8158ca8663a72f6abb78c2603
          imagePullPolicy: IfNotPresent
          name: echo-same-node
          ports:
          - containerPort: 8080
            name: http-8080
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 1
            periodSeconds: 1
            successThreshold: 1
            timeoutSeconds: 2
          resources: {}
          securityContext:
            capabilities:
              add:
              - NET_RAW
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - args:
          - -conf
          - /etc/coredns/Corefile
          image: registry.k8s.io/coredns/coredns:v1.12.0@sha256:40384aa1f5ea6bfdc77997d243aec73da05f27aed0c5e9d65bfa98933c519d97
          imagePullPolicy: IfNotPresent
          name: dns-test-server
          ports:
          - containerPort: 53
            name: dns-53
            protocol: TCP
          - containerPort: 53
            name: dns-udp-53
            protocol: UDP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: 8181
              scheme: HTTP
            initialDelaySeconds: 1
            periodSeconds: 1
            successThreshold: 1
            timeoutSeconds: 2
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/coredns
            name: coredns-config-volume
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: echo-same-node
        serviceAccountName: echo-same-node
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: Corefile
              path: Corefile
            name: coredns-configmap
          name: coredns-config-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-08-13T15:27:42Z"
      lastUpdateTime: "2025-08-13T15:27:42Z"
      message: ReplicaSet "echo-same-node-5f44c8d48c" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-10-18T20:44:43Z"
      lastUpdateTime: "2025-10-18T20:44:43Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: border0-con
      meta.helm.sh/release-namespace: default
    creationTimestamp: "2025-12-16T07:27:23Z"
    generation: 1
    labels:
      app.kubernetes.io/instance: border0-con
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: border0-connector
      app.kubernetes.io/version: latest
      helm.sh/chart: border0-connector-0.6.0
    name: border0-con-border0-connector
    namespace: default
    resourceVersion: "55567462"
    uid: 4cb3d34c-a66c-478d-99d8-0c1814dd73d1
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: border0-con
        app.kubernetes.io/name: border0-connector
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app.kubernetes.io/instance: border0-con
          app.kubernetes.io/name: border0-connector
      spec:
        containers:
        - args:
          - connector
          - start
          - --invite=mTe9Ori1N1y
          - --token-persistence-mode=k8s-secret
          - --k8s-secret=border0-con-border0-connector-config
          image: ghcr.io/borderzero/border0:latest
          imagePullPolicy: Always
          name: border0-connector
          resources: {}
          securityContext:
            capabilities:
              add:
              - NET_ADMIN
              - NET_RAW
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /dev/net/tun
            name: dev-net-tun
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: border0-con-border0-connector
        serviceAccountName: border0-con-border0-connector
        terminationGracePeriodSeconds: 30
        volumes:
        - name: config
          secret:
            defaultMode: 420
            optional: true
            secretName: border0-con-border0-connector-config
        - hostPath:
            path: /dev/net/tun
            type: ""
          name: dev-net-tun
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-12-16T07:27:30Z"
      lastUpdateTime: "2025-12-16T07:27:30Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-12-16T07:27:23Z"
      lastUpdateTime: "2025-12-16T07:27:30Z"
      message: ReplicaSet "border0-con-border0-connector-84bb6dfc7d" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: nfs-provisioner
      meta.helm.sh/release-namespace: default
    creationTimestamp: "2025-01-13T08:17:16Z"
    generation: 1
    labels:
      app: nfs-subdir-external-provisioner
      app.kubernetes.io/managed-by: Helm
      chart: nfs-subdir-external-provisioner-4.0.18
      heritage: Helm
      release: nfs-provisioner
    name: nfs-provisioner-nfs-subdir-external-provisioner
    namespace: default
    resourceVersion: "53479477"
    uid: 563ff062-6692-442d-8572-ec1f159fea4f
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: nfs-subdir-external-provisioner
        release: nfs-provisioner
    strategy:
      type: Recreate
    template:
      metadata:
        labels:
          app: nfs-subdir-external-provisioner
          release: nfs-provisioner
      spec:
        containers:
        - env:
          - name: PROVISIONER_NAME
            value: cluster.local/nfs-provisioner-nfs-subdir-external-provisioner
          - name: NFS_SERVER
            value: 192.168.1.42
          - name: NFS_PATH
            value: /volume1/minio-backup
          image: registry.k8s.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2
          imagePullPolicy: IfNotPresent
          name: nfs-subdir-external-provisioner
          resources: {}
          securityContext: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /persistentvolumes
            name: nfs-subdir-external-provisioner-root
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: nfs-provisioner-nfs-subdir-external-provisioner
        serviceAccountName: nfs-provisioner-nfs-subdir-external-provisioner
        terminationGracePeriodSeconds: 30
        volumes:
        - name: nfs-subdir-external-provisioner-root
          nfs:
            path: /volume1/minio-backup
            server: 192.168.1.42
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-01-13T08:17:16Z"
      lastUpdateTime: "2025-01-13T08:17:19Z"
      message: ReplicaSet "nfs-provisioner-nfs-subdir-external-provisioner-65fc65c4dc"
        has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-08T22:07:11Z"
      lastUpdateTime: "2025-12-08T22:07:11Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2025-07-28T15:23:12Z"
    generation: 1
    labels:
      app: nginx
    name: nginx-deployment
    namespace: default
    resourceVersion: "39327136"
    uid: 6752bdd6-a3a1-4e68-8cb8-ac6f2a854d13
  spec:
    progressDeadlineSeconds: 600
    replicas: 3
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: nginx
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app: nginx
      spec:
        containers:
        - image: nginx:latest
          imagePullPolicy: Always
          name: nginx
          ports:
          - containerPort: 80
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 3
    conditions:
    - lastTransitionTime: "2025-08-13T09:30:28Z"
      lastUpdateTime: "2025-08-13T09:30:31Z"
      message: ReplicaSet "nginx-deployment-54b9c68f67" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-10-15T12:57:28Z"
      lastUpdateTime: "2025-10-15T12:57:28Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 3
    replicas: 3
    updatedReplicas: 3
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2025-07-30T16:08:21Z"
    generation: 1
    labels:
      app: web
      tier: frontend
    name: web-frontend
    namespace: default
    resourceVersion: "39327013"
    uid: 13523a51-b558-4019-a5a8-1955835adfae
  spec:
    progressDeadlineSeconds: 600
    replicas: 3
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: web
        tier: frontend
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app: web
          tier: frontend
      spec:
        containers:
        - image: nginx:latest
          imagePullPolicy: Always
          name: web-frontend
          ports:
          - containerPort: 80
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 3
    conditions:
    - lastTransitionTime: "2025-08-13T09:30:32Z"
      lastUpdateTime: "2025-08-13T09:30:33Z"
      message: ReplicaSet "web-frontend-6bc4d89dd" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-10-15T12:57:26Z"
      lastUpdateTime: "2025-10-15T12:57:26Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 3
    replicas: 3
    updatedReplicas: 3
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "4"
    creationTimestamp: "2025-11-24T16:01:32Z"
    generation: 5
    labels:
      app: esphome
      app.kubernetes.io/instance: esphome
    name: esphome
    namespace: home-assistant
    resourceVersion: "54067993"
    uid: 23672c84-1199-418f-8c24-80e3005aff28
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: esphome
    strategy:
      type: Recreate
    template:
      metadata:
        labels:
          app: esphome
      spec:
        containers:
        - env:
          - name: ESPHOME_DASHBOARD_USE_PING
            value: "true"
          image: ghcr.io/esphome/esphome:2025.11.1
          imagePullPolicy: IfNotPresent
          name: esphome
          ports:
          - containerPort: 6052
            name: http
            protocol: TCP
          resources:
            limits:
              cpu: "1"
              memory: 1Gi
            requests:
              cpu: 100m
              memory: 256Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /config
            name: config
        dnsPolicy: ClusterFirstWithHostNet
        hostNetwork: true
        nodeSelector:
          kubernetes.io/hostname: worker
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: config
          persistentVolumeClaim:
            claimName: esphome
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-11-24T16:43:07Z"
      lastUpdateTime: "2025-12-05T11:32:52Z"
      message: ReplicaSet "esphome-857d48db79" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-10T22:40:47Z"
      lastUpdateTime: "2025-12-10T22:40:47Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 5
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      configmap-checksum: '{{ include (print $.Template.BasePath "/configmap.yaml")
        . | sha256sum }}'
      deployment.kubernetes.io/revision: "9"
      values-checksum: bb013530a10f2c3a730621be399eb08eda249b54fdec01a23ad6f5a2ad063994
    creationTimestamp: "2025-01-21T17:58:17Z"
    generation: 59
    labels:
      app.kubernetes.io/instance: homepage
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: homepage
      app.kubernetes.io/version: v0.9.6
      helm.sh/chart: homepage-2.0.1
    name: homepage
    namespace: homepage
    resourceVersion: "54066930"
    uid: 80b8fe8d-8951-4848-864d-1b641ddfdf97
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 3
    selector:
      matchLabels:
        app.kubernetes.io/instance: homepage
        app.kubernetes.io/name: homepage
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-01-22T09:20:39+01:00"
        labels:
          app.kubernetes.io/instance: homepage
          app.kubernetes.io/name: homepage
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: HOMEPAGE_VAR_GRAFANA_USER
            value: admin
          - name: HOMEPAGE_VAR_GRAFANA_PASSWORD
            value: prom-operator
          - name: HOMEPAGE_VAR_RADARR_API_KEY
            value: YOUR_RADARR_API_KEY
          - name: HOMEPAGE_VAR_HOMEASSISTANT_TOKEN
            value: YOUR_HOMEASSISTANT_TOKEN
          image: ghcr.io/gethomepage/homepage:v0.9.6
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: 3000
            timeoutSeconds: 1
          name: homepage
          ports:
          - containerPort: 3000
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: 3000
            timeoutSeconds: 1
          resources: {}
          startupProbe:
            failureThreshold: 30
            periodSeconds: 5
            successThreshold: 1
            tcpSocket:
              port: 3000
            timeoutSeconds: 1
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/config/bookmarks.yaml
            name: homepage-config
            subPath: bookmarks.yaml
          - mountPath: /app/config/docker.yaml
            name: homepage-config
            subPath: docker.yaml
          - mountPath: /app/config/kubernetes.yaml
            name: homepage-config
            subPath: kubernetes.yaml
          - mountPath: /app/config/services.yaml
            name: homepage-config
            subPath: services.yaml
          - mountPath: /app/config/settings.yaml
            name: homepage-config
            subPath: settings.yaml
          - mountPath: /app/config/widgets.yaml
            name: homepage-config
            subPath: widgets.yaml
          - mountPath: /app/config/logs
            name: logs
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: homepage
        serviceAccountName: homepage
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: homepage
          name: homepage-config
        - name: logs
          persistentVolumeClaim:
            claimName: homepage
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-11-23T23:08:21Z"
      lastUpdateTime: "2025-11-23T23:34:47Z"
      message: ReplicaSet "homepage-66bc76789" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-10T22:40:09Z"
      lastUpdateTime: "2025-12-10T22:40:09Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 59
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "7"
      meta.helm.sh/release-name: cilium
      meta.helm.sh/release-namespace: kube-system
    creationTimestamp: "2025-08-13T09:53:54Z"
    generation: 7
    labels:
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: cilium-operator
      app.kubernetes.io/part-of: cilium
      io.cilium/app: operator
      name: cilium-operator
    name: cilium-operator
    namespace: kube-system
    resourceVersion: "56226975"
    uid: c49e0f2e-0f58-4502-97e9-3da3c3695315
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        io.cilium/app: operator
        name: cilium-operator
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 100%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-08-14T19:34:58+02:00"
          prometheus.io/port: "9963"
          prometheus.io/scrape: "true"
        labels:
          app.kubernetes.io/name: cilium-operator
          app.kubernetes.io/part-of: cilium
          io.cilium/app: operator
          name: cilium-operator
      spec:
        affinity:
          podAntiAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  io.cilium/app: operator
              topologyKey: kubernetes.io/hostname
        automountServiceAccountToken: true
        containers:
        - args:
          - --config-dir=/tmp/cilium/config-map
          - --debug=$(CILIUM_DEBUG)
          command:
          - cilium-operator-generic
          env:
          - name: K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: CILIUM_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: CILIUM_DEBUG
            valueFrom:
              configMapKeyRef:
                key: debug
                name: cilium-config
                optional: true
          - name: KUBERNETES_SERVICE_HOST
            value: 100.113.23.108
          - name: KUBERNETES_SERVICE_PORT
            value: "6443"
          image: quay.io/cilium/operator-generic:v1.18.4@sha256:1b22b9ff28affdf574378a70dade4ef835b00b080c2ee2418530809dd62c3012
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              host: 127.0.0.1
              path: /healthz
              port: 9234
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 3
          name: cilium-operator
          ports:
          - containerPort: 9963
            hostPort: 9963
            name: prometheus
            protocol: TCP
          readinessProbe:
            failureThreshold: 5
            httpGet:
              host: 127.0.0.1
              path: /healthz
              port: 9234
              scheme: HTTP
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /tmp/cilium/config-map
            name: cilium-config-path
            readOnly: true
        dnsPolicy: ClusterFirst
        hostNetwork: true
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: cilium-operator
        serviceAccountName: cilium-operator
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: node-role.kubernetes.io/control-plane
          operator: Exists
        - key: node-role.kubernetes.io/master
          operator: Exists
        - key: node.kubernetes.io/not-ready
          operator: Exists
        - key: node.cloudprovider.kubernetes.io/uninitialized
          operator: Exists
        - key: node.cilium.io/agent-not-ready
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: cilium-config
          name: cilium-config-path
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-08-13T09:53:54Z"
      lastUpdateTime: "2025-08-13T09:53:54Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-08-13T09:53:54Z"
      lastUpdateTime: "2025-12-18T16:33:11Z"
      message: ReplicaSet "cilium-operator-65d45c9cd4" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 7
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "8"
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/6xV33PbNgz+V3Z4lmIrbhtXd3vo4mzttfV8ddKXXq5HU5DFmSI4EnKi5fy/7yDZjt3mR7vbk0QSAD98wAfegfLmM4ZoyEEOyvs4WGeQwMq4AnKYoLfU1ugYEqiRVaFYQX4HyjlixYZclCUt/kLNEfkkGDrRitniiaGBkSCQPHpONw5DulyvIIfVKB6crLPkl/fGFb++KQpyz4ZwqkbIQVPAwsUfMo9eafFZNQtMYxsZa9gkYNUCbZfUahxT5f3OpI8rv8EhY5Ro22vPKeBkOn/i2krFCnJYaDwdj05fj8dZdvZipIaj8Su1eJkNy9Py1RmWZy9OXwz1yzMB8l1KT4COHrVADrg2Usu3JjKF9oOpDUM+TCCiRc0UxKhWrKsPT6W5kZAcFOOy7cKStcYtr3yhGPsQt1dOrZWxamER8myTALdekH06spV9rL3d+R200JNEbw6S0uRYGYchQv7lDlRYyg+kmlwJCQyQ9WDL0kAqURqLcJ2AqdVSEAXldIVhUJsQxCzdGu++eXaSnZ6MYOsxa6ydkTW6hRzelVPiWcDYS8CaNTqMcRZo0SVUKmObgJdVwFiRLSAfJVAx+z+Q5dwrlroPKlSWK0jAU2DIx8OxFEVX2NX47eXlTKgyzrBRdoJWtXPU5IoI+athAh6DoWK/lYlzozXGeHBzlgCbGqnhe8OH+kgg9FTumZ11qF6O9tZby0BMmizkcDURhM+4pKz9sdvl+YNur7MDxxo5GB0fcLxOIKAqzH+iXDzbe8azcfajjH9P+OlP8B0wUhM0dq1tRYGxb/2agrRUdjb8aKAz/LvB2J9q38jRcFh3g3Zr2luKFFA3wXB7To7xtktTWUs3s2DWxuISL6JWtpvHkJfKRkxAK68Wxho2PRRVFCKb6cXl19/eTSdf5xefPr87vxClFIG8nClr4XrTk/6ns+0nIv7dWNwOmpxDg5sE1mSbGj9S47Z9VMvvbMv7gRzhoPtcaZZp7wn3N+xiPh5joJvIVB+E6tbpMxGvpXkKF/dKnmCpGisidlTg/GAeHo90ipCDNa65lRr5YKgj3qoYpz2Ano1U2yYyhlQHw0YrC1KmsDYa32gtyUy/FR6TxbB7NL/cwQoF2PnWv3voYpdCAuTFUvDBxa2RJhGOsCxRM+QwpbmusGisZN6HkazSQBZPjvMR5QWyqbfK4cORrwWaJ0vLdu6Fx3NyMv7Nrr7dqJ7/9BNSq9v5Cm96pWwveN+BPYZYUeSuuAncVOiuXFRsYmn6twUmNCXe5ys8/O94dqtvuPuH3GOgdnjeuPZGtR2HfSvuJ2tplh+VFziGsT6q+O6RSnbDar8j2fVGUyrwLUl99lb3W3LdN3N984jWttP3Hs2xX7qXF3npTGX3Mn9Kb5vrzWaz+TcAAP//lhToZj8KAAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: k3s.cattle.io/v1, Kind=Addon
      objectset.rio.cattle.io/owner-name: coredns
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2024-12-21T11:29:46Z"
    generation: 8
    labels:
      k8s-app: kube-dns
      kubernetes.io/name: CoreDNS
      objectset.rio.cattle.io/hash: bce283298811743a0386ab510f2f67ef74240c57
    name: coredns
    namespace: kube-system
    resourceVersion: "40548575"
    uid: 6ac494c5-ac2a-471a-bebc-99f69542e72e
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 0
    selector:
      matchLabels:
        k8s-app: kube-dns
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-01-12T17:59:24+01:00"
        labels:
          k8s-app: kube-dns
      spec:
        containers:
        - args:
          - -conf
          - /etc/coredns/Corefile
          image: rancher/mirrored-coredns-coredns:1.12.3
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /health
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: coredns
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 9153
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: 8181
              scheme: HTTP
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - all
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/coredns
            name: config-volume
            readOnly: true
          - mountPath: /etc/coredns/custom
            name: custom-config-volume
            readOnly: true
        dnsPolicy: Default
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: coredns
        serviceAccountName: coredns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        topologySpreadConstraints:
        - labelSelector:
            matchLabels:
              k8s-app: kube-dns
          maxSkew: 1
          topologyKey: kubernetes.io/hostname
          whenUnsatisfiable: DoNotSchedule
        - labelSelector:
            matchLabels:
              k8s-app: kube-dns
          maxSkew: 1
          topologyKey: topology.kubernetes.io/zone
          whenUnsatisfiable: ScheduleAnyway
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: Corefile
              path: Corefile
            - key: NodeHosts
              path: NodeHosts
            name: coredns
          name: config-volume
        - configMap:
            defaultMode: 420
            name: coredns-custom
            optional: true
          name: custom-config-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-12-21T11:29:49Z"
      lastUpdateTime: "2024-12-21T11:29:49Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-12-21T11:29:49Z"
      lastUpdateTime: "2025-10-21T16:27:37Z"
      message: ReplicaSet "coredns-844d4fcbb5" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 8
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "7"
      meta.helm.sh/release-name: cilium
      meta.helm.sh/release-namespace: kube-system
    creationTimestamp: "2025-08-13T10:40:37Z"
    generation: 7
    labels:
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: hubble-relay
      app.kubernetes.io/part-of: cilium
      k8s-app: hubble-relay
    name: hubble-relay
    namespace: kube-system
    resourceVersion: "56227291"
    uid: a51e67d7-e235-437f-997d-5ddbf56f879f
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: hubble-relay
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        labels:
          app.kubernetes.io/name: hubble-relay
          app.kubernetes.io/part-of: cilium
          k8s-app: hubble-relay
      spec:
        affinity:
          podAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  k8s-app: cilium
              topologyKey: kubernetes.io/hostname
        automountServiceAccountToken: false
        containers:
        - args:
          - serve
          command:
          - hubble-relay
          image: quay.io/cilium/hubble-relay:v1.18.4@sha256:6d350cb1c84b847adb152173debef1f774126c69de21a5921a1e6a23b8779723
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 12
            grpc:
              port: 4222
              service: ""
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 10
          name: hubble-relay
          ports:
          - containerPort: 4245
            name: grpc
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            grpc:
              port: 4222
              service: ""
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 3
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            runAsGroup: 65532
            runAsNonRoot: true
            runAsUser: 65532
            seccompProfile:
              type: RuntimeDefault
          startupProbe:
            failureThreshold: 20
            grpc:
              port: 4222
              service: ""
            initialDelaySeconds: 10
            periodSeconds: 3
            successThreshold: 1
            timeoutSeconds: 1
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/hubble-relay
            name: config
            readOnly: true
          - mountPath: /var/lib/hubble-relay/tls
            name: tls
            readOnly: true
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65532
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: hubble-relay
        serviceAccountName: hubble-relay
        terminationGracePeriodSeconds: 1
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: config.yaml
              path: config.yaml
            name: hubble-relay-config
          name: config
        - name: tls
          projected:
            defaultMode: 256
            sources:
            - secret:
                items:
                - key: tls.crt
                  path: client.crt
                - key: tls.key
                  path: client.key
                - key: ca.crt
                  path: hubble-server-ca.crt
                name: hubble-relay-client-certs
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-08-13T10:40:37Z"
      lastUpdateTime: "2025-08-13T10:40:37Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-08-13T15:17:07Z"
      lastUpdateTime: "2025-12-18T16:33:49Z"
      message: ReplicaSet "hubble-relay-86b5fc8778" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 7
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "4"
      meta.helm.sh/release-name: cilium
      meta.helm.sh/release-namespace: kube-system
    creationTimestamp: "2025-08-13T10:40:37Z"
    generation: 4
    labels:
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: hubble-ui
      app.kubernetes.io/part-of: cilium
      k8s-app: hubble-ui
    name: hubble-ui
    namespace: kube-system
    resourceVersion: "40548712"
    uid: 41405b0c-703b-4faf-a0d4-62adb6312146
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: hubble-ui
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        labels:
          app.kubernetes.io/name: hubble-ui
          app.kubernetes.io/part-of: cilium
          k8s-app: hubble-ui
      spec:
        automountServiceAccountToken: true
        containers:
        - image: quay.io/cilium/hubble-ui:v0.13.3@sha256:661d5de7050182d495c6497ff0b007a7a1e379648e60830dd68c4d78ae21761d
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8081
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: frontend
          ports:
          - containerPort: 8081
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 8081
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/nginx/conf.d/default.conf
            name: hubble-ui-nginx-conf
            subPath: nginx.conf
          - mountPath: /tmp
            name: tmp-dir
        - env:
          - name: EVENTS_SERVER_PORT
            value: "8090"
          - name: FLOWS_API_ADDR
            value: hubble-relay:80
          image: quay.io/cilium/hubble-ui-backend:v0.13.3@sha256:db1454e45dc39ca41fbf7cad31eec95d99e5b9949c39daaad0fa81ef29d56953
          imagePullPolicy: IfNotPresent
          name: backend
          ports:
          - containerPort: 8090
            name: grpc
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 1001
          runAsGroup: 1001
          runAsUser: 1001
        serviceAccount: hubble-ui
        serviceAccountName: hubble-ui
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: hubble-ui-nginx
          name: hubble-ui-nginx-conf
        - emptyDir: {}
          name: tmp-dir
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-08-13T10:40:37Z"
      lastUpdateTime: "2025-08-13T10:40:37Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-08-13T15:17:08Z"
      lastUpdateTime: "2025-10-18T22:58:09Z"
      message: ReplicaSet "hubble-ui-576dcd986f" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 4
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "3"
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/5RUUU/zRhD8K9U+207yBaLIUh8ioGpVCBGIvqCo2pzXyZHz3elu42JF/u/Vxg4ElUC/J/t8u+OZ2bnbA3r9F4WonYUc0Ps4qEeQwFbbAnK4Jm9cU5FlSKAixgIZId8DWusYWTsbZelWL6Q4EmdBu0whs6FMu4EWEEjO7rt/LIV0XW8hh+04nuzUo+SXP7Utfp0VhbPfQlisCHIwTqFJI7uAa/pfTdGjks7tbkVpbCJTBW0CBldkvpS2wbiBHEbTcTm+VJPLslyp8XByMRmOy4txObqcDoupmkzxR4Gr4kJAP5D0yJvUB1drMZ8CdPtn+ERPStgE6up/1yKyudWVZsiHCUQypNgFKaqQ1eb2TQF6f/6vrYBzQKZ1c/iBM0bb9ZMvkKkDe32yWKM2uDIE+ahNgBsvHB8+1Mp3qrw59p2kxfwEl16ocpZRWwoR8mdZVhVKJJ/P2xcZg+Q0TZWzpV5DAgNiNehW/SN7ic7CMgGy9QG5H8ri/vrv+ezu5nExu7qBBGo0O/otuErIlJpM8UDl2/sCWYZ/1Ji9T65t22UCupL85RDQqg2Fweec83qYDbPxD+gbFjtjFs5o1UAOf5Rzx4tAsTt832WndmZX0Z3bWe4cq+S153lqwztW9yHtOqFdCnHrCno8iZLEMFhiiodjE4WCtrtXmbYP2gXNzZXBGOcdZpfYVGBSFTRrhUZGQ6HWimZKCav5V1rSvjbFrhgSYGcoHC+b5z1sSQy66uEPF0S8t6aRA++lUrjDzauOHKFN9kBlSYohh7l7VBsqdkYuhw7mQDU4Q9lHrRLA4EzqDVr6HHl5tP2YUfHzDr0Y99959aFsz/vftu2/AQAA///dDGDzkQUAAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: k3s.cattle.io/v1, Kind=Addon
      objectset.rio.cattle.io/owner-name: local-storage
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2024-12-21T11:29:46Z"
    generation: 3
    labels:
      objectset.rio.cattle.io/hash: 183f35c65ffbc3064603f43f1580d8c68a2dabd4
    name: local-path-provisioner
    namespace: kube-system
    resourceVersion: "40548625"
    uid: 9162dc7a-5984-470e-8949-920f18d2fa0e
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 0
    selector:
      matchLabels:
        app: local-path-provisioner
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        labels:
          app: local-path-provisioner
      spec:
        containers:
        - command:
          - local-path-provisioner
          - start
          - --config
          - /etc/config/config.json
          env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: rancher/local-path-provisioner:v0.0.32
          imagePullPolicy: IfNotPresent
          name: local-path-provisioner
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config/
            name: config-volume
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: local-path-provisioner-service-account
        serviceAccountName: local-path-provisioner-service-account
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: local-path-config
          name: config-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-12-21T11:29:49Z"
      lastUpdateTime: "2024-12-21T11:29:49Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-12-21T11:29:49Z"
      lastUpdateTime: "2025-10-18T20:44:35Z"
      message: ReplicaSet "local-path-provisioner-578895bd58" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 3
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "4"
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/5xVYW8aORD9K6f5vJvsEkjSlfiACFeqS1NU6J1OVYSMdwAfXtvnmaXhIv77aXaTlFxD0+sXtNjj5zfvjWfuQQXzO0Yy3kEBKgQ63eaQwMa4Egq4wmD9rkLHkECFrErFCop7UM55Vmy8I/nrF3+hZkI+icafaMVs8cT4UyMgkBzd918cxnS13UABmzM62NnmyS+/GVf2B2Xp3asQTlUIhVCMRlNKGLcY0/KQ/usAFJQWlE29wJR2xFjBPgGrFmibNDeXlKoQvrnoO+hrRWsoAPMMO90e5mfYPVcXnZ5+U5Zl2V2+wUXn7M0y715cXHSXpdz3Yi7Qrh+hSAG1EIy4NeLl2BD7uLs2lWEosgQILWr2UYIqxXp9/XpSewHmqBhXuwbcW2vc6lMoFWMLdPfJqa0yVi0sQpHvE+BdEH4fn8XKOlbBPp47KKQfEPeoJAeJa+9YGYeRoPh8Dyqu5APSVGPktDSxf8pVgATSlFDXEdPgI/fzrNPLmlUR1CKnIeISY8QyVWUZkSiVjKj/zjFGp+y7STK6e/oce+KG2yFETZg6X2JKrLim5qYmoKWfRiRva3k7/bxHzQ5bSrUJa4wp1YaR+rPr6Xw0vBqP5Hc6mP/xbjaeD0bTead3Pn87fD+fjgdnl93ka9zHH4r6D1reuXyM6/TOj6EdjTpAG44Hw/Ggk80nH67/zM+y3ktg3wTBbQKmUitxNyqn1xhPKxOjFwee211ss5PLE3HLmi06JJpEv2gKaqmMrSPO1hFp7W0JxVkCa+bwFln2g2J5hKdy8B9IoHGkaCJEf9JrbOprPJtNplJWxhk2yl6hVbspau9KguI8SyBgNL58WsrladVaI9HB5XkCbCr0NX8N/M67FjZt2T5V8aQh2FTn07lHtiF69tpbKGA2nMD+NoGIqjQ/pYic3P28JN8q0vkfgshDqKNGalvX3zUSN9861FBAnmVVM3YqH3dQwEX23rRNSV6w4d3QO8a7Jh9lrf8yiWZrLK5wRFrZZjpBsVSWsJXog7O7j97zr8biQ+8sONayW7sB3Xgnu8/WPhFGMSLL9glsva0rfO9r9+BXJZ+TBynb/vJgFldBug7sb8Uf6QbTgw4snSI6ZKRmABEUYI2r70TnEI1vkrOK6KZFa8m2TUVHw0YrKyZh3BqNA62Fx82R8mJvMT6O6s/3sEERc/gA04xXEmVkiAWJFI4wujNixj65B1wuUUtx3PipXmNZW+l3LUxDKXqLJ89zkkqO3qbBKocvI98+CtrSwirw7sqIPvuXZNzv9/8GAAD//0w/ypmuCAAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: k3s.cattle.io/v1, Kind=Addon
      objectset.rio.cattle.io/owner-name: metrics-server-deployment
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2024-12-21T11:29:47Z"
    generation: 4
    labels:
      k8s-app: metrics-server
      objectset.rio.cattle.io/hash: e10e245e13e46a725c9dddd4f9eb239f147774fd
    name: metrics-server
    namespace: kube-system
    resourceVersion: "53479781"
    uid: 369a0949-fd98-4dac-9670-2b2324081595
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 0
    selector:
      matchLabels:
        k8s-app: metrics-server
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-08-13T11:51:57+02:00"
        labels:
          k8s-app: metrics-server
        name: metrics-server
      spec:
        containers:
        - args:
          - --cert-dir=/tmp
          - --secure-port=10250
          - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
          - --kubelet-use-node-status-port
          - --metric-resolution=15s
          - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305
          image: rancher/mirrored-metrics-server:v0.8.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /livez
              port: https
              scheme: HTTPS
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: metrics-server
          ports:
          - containerPort: 10250
            name: https
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: https
              scheme: HTTPS
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp
            name: tmp-dir
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metrics-server
        serviceAccountName: metrics-server
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        volumes:
        - emptyDir: {}
          name: tmp-dir
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-12-21T11:29:49Z"
      lastUpdateTime: "2024-12-21T11:29:49Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-08-13T15:27:49Z"
      lastUpdateTime: "2025-10-18T20:54:17Z"
      message: ReplicaSet "metrics-server-749b965bcb" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 4
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2025-10-23T17:23:16Z"
    generation: 4
    labels:
      app.kubernetes.io/instance: sealed-secrets
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: sealed-secrets
      app.kubernetes.io/part-of: sealed-secrets
      app.kubernetes.io/version: 0.27.2
      helm.sh/chart: sealed-secrets-2.16.2
    name: sealed-secrets-controller
    namespace: kube-system
    resourceVersion: "54064889"
    uid: 7ecf450d-7ce6-4448-af9b-6ed8a4630f45
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: sealed-secrets
        app.kubernetes.io/name: sealed-secrets
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app.kubernetes.io/instance: sealed-secrets
          app.kubernetes.io/name: sealed-secrets
      spec:
        containers:
        - args:
          - --update-status
          - --key-prefix
          - sealed-secrets-key
          - --listen-addr
          - :8080
          - --listen-metrics-addr
          - :8081
          command:
          - controller
          env:
          - name: GOMAXPROCS
            valueFrom:
              resourceFieldRef:
                divisor: "0"
                resource: limits.cpu
          - name: GOMEMLIMIT
            valueFrom:
              resourceFieldRef:
                divisor: "0"
                resource: limits.memory
          image: docker.io/bitnami/sealed-secrets-controller:0.27.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: http
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: controller
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          - containerPort: 8081
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: http
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              cpu: 200m
              memory: 256Mi
            requests:
              cpu: 50m
              memory: 64Mi
          securityContext:
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1001
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp
            name: tmp
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
        serviceAccount: sealed-secrets-controller
        serviceAccountName: sealed-secrets-controller
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: tmp
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-10-23T17:23:16Z"
      lastUpdateTime: "2025-10-23T17:23:41Z"
      message: ReplicaSet "sealed-secrets-controller-69fd44b646" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-10T22:39:26Z"
      lastUpdateTime: "2025-12-10T22:39:26Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 4
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "10"
      meta.helm.sh/release-name: traefik
      meta.helm.sh/release-namespace: kube-system
    creationTimestamp: "2024-12-21T11:30:01Z"
    generation: 10
    labels:
      app.kubernetes.io/instance: traefik-kube-system
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: traefik
      helm.sh/chart: traefik-34.2.1_up34.2.0
    name: traefik
    namespace: kube-system
    resourceVersion: "41489308"
    uid: 9f4e7f23-d7c7-48fc-ac71-d8de341b8043
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: traefik-kube-system
        app.kubernetes.io/name: traefik
    strategy:
      rollingUpdate:
        maxSurge: 1
        maxUnavailable: 0
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-10-25T22:09:13+02:00"
          prometheus.io/path: /metrics
          prometheus.io/port: "9100"
          prometheus.io/scrape: "true"
        labels:
          app.kubernetes.io/instance: traefik-kube-system
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: traefik
          helm.sh/chart: traefik-34.2.1_up34.2.0
      spec:
        automountServiceAccountToken: true
        containers:
        - args:
          - --global.checknewversion
          - --global.sendanonymoususage
          - --entryPoints.metrics.address=:9100/tcp
          - --entryPoints.traefik.address=:8080/tcp
          - --entryPoints.web.address=:8000/tcp
          - --entryPoints.websecure.address=:8443/tcp
          - --api.dashboard=true
          - --ping=true
          - --metrics.prometheus=true
          - --metrics.prometheus.entrypoint=metrics
          - --providers.kubernetescrd
          - --providers.kubernetescrd.allowEmptyServices=true
          - --providers.kubernetesingress
          - --providers.kubernetesingress.allowEmptyServices=true
          - --providers.kubernetesingress.ingressendpoint.publishedservice=kube-system/traefik
          - --entryPoints.websecure.http.tls=true
          - --log.level=INFO
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: rancher/mirrored-library-traefik:3.3.6
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /ping
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          name: traefik
          ports:
          - containerPort: 9100
            name: metrics
            protocol: TCP
          - containerPort: 8080
            name: traefik
            protocol: TCP
          - containerPort: 8000
            name: web
            protocol: TCP
          - containerPort: 8443
            name: websecure
            protocol: TCP
          readinessProbe:
            failureThreshold: 1
            httpGet:
              path: /ping
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /data
            name: data
          - mountPath: /tmp
            name: tmp
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/hostname: beelink
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          runAsGroup: 65532
          runAsNonRoot: true
          runAsUser: 65532
        serviceAccount: traefik
        serviceAccountName: traefik
        terminationGracePeriodSeconds: 60
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        volumes:
        - emptyDir: {}
          name: data
        - emptyDir: {}
          name: tmp
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-10-23T08:53:08Z"
      lastUpdateTime: "2025-10-23T08:53:08Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-12-21T11:30:01Z"
      lastUpdateTime: "2025-10-25T20:09:16Z"
      message: ReplicaSet "traefik-6cc4d66dd9" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 10
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      driver.longhorn.io/git-commit: 29b7fda2692c8df5b1aa18c477f77863c7acc1e7
      driver.longhorn.io/version: v1.10.1
      longhorn.io/last-applied-tolerations: '[]'
    creationTimestamp: "2025-11-13T08:21:28Z"
    generation: 1
    labels:
      app: csi-attacher
      longhorn.io/managed-by: longhorn-manager
    name: csi-attacher
    namespace: longhorn-system
    resourceVersion: "54065113"
    uid: 3c5dbf93-0111-4841-a32a-bd996d43a01b
  spec:
    progressDeadlineSeconds: 600
    replicas: 3
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: csi-attacher
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app: csi-attacher
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: app
                    operator: In
                    values:
                    - csi-attacher
                topologyKey: kubernetes.io/hostname
              weight: 1
        containers:
        - args:
          - --v=2
          - --csi-address=$(ADDRESS)
          - --timeout=1m50s
          - --leader-election
          - --leader-election-namespace=$(POD_NAMESPACE)
          - --kube-api-qps=50
          - --kube-api-burst=100
          - --http-endpoint=:8000
          env:
          - name: ADDRESS
            value: /csi/csi.sock
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          image: longhornio/csi-attacher:v4.10.0-20251030
          imagePullPolicy: IfNotPresent
          name: csi-attacher
          ports:
          - containerPort: 8000
            name: csi-attacher
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /csi/
            name: socket-dir
        dnsPolicy: ClusterFirst
        priorityClassName: longhorn-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: longhorn-service-account
        serviceAccountName: longhorn-service-account
        terminationGracePeriodSeconds: 30
        volumes:
        - hostPath:
            path: /var/lib/kubelet/plugins/driver.longhorn.io
            type: DirectoryOrCreate
          name: socket-dir
  status:
    availableReplicas: 3
    conditions:
    - lastTransitionTime: "2025-11-13T08:21:28Z"
      lastUpdateTime: "2025-11-13T08:21:34Z"
      message: ReplicaSet "csi-attacher-5857549d6f" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-10T22:39:34Z"
      lastUpdateTime: "2025-12-10T22:39:34Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 3
    replicas: 3
    updatedReplicas: 3
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      driver.longhorn.io/git-commit: 29b7fda2692c8df5b1aa18c477f77863c7acc1e7
      driver.longhorn.io/version: v1.10.1
      longhorn.io/last-applied-tolerations: '[]'
    creationTimestamp: "2025-11-13T08:21:30Z"
    generation: 1
    labels:
      app: csi-provisioner
      longhorn.io/managed-by: longhorn-manager
    name: csi-provisioner
    namespace: longhorn-system
    resourceVersion: "54065105"
    uid: a1532c31-2521-4fae-ab9e-cbd362a069b6
  spec:
    progressDeadlineSeconds: 600
    replicas: 3
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: csi-provisioner
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app: csi-provisioner
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: app
                    operator: In
                    values:
                    - csi-provisioner
                topologyKey: kubernetes.io/hostname
              weight: 1
        containers:
        - args:
          - --v=2
          - --csi-address=$(ADDRESS)
          - --timeout=1m50s
          - --leader-election
          - --leader-election-namespace=$(POD_NAMESPACE)
          - --default-fstype=ext4
          - --enable-capacity
          - --capacity-ownerref-level=2
          - --kube-api-qps=50
          - --kube-api-burst=100
          - --http-endpoint=:8000
          env:
          - name: ADDRESS
            value: /csi/csi.sock
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          image: longhornio/csi-provisioner:v5.3.0-20251030
          imagePullPolicy: IfNotPresent
          name: csi-provisioner
          ports:
          - containerPort: 8000
            name: csi-provisioner
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /csi/
            name: socket-dir
        dnsPolicy: ClusterFirst
        priorityClassName: longhorn-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: longhorn-service-account
        serviceAccountName: longhorn-service-account
        terminationGracePeriodSeconds: 30
        volumes:
        - hostPath:
            path: /var/lib/kubelet/plugins/driver.longhorn.io
            type: DirectoryOrCreate
          name: socket-dir
  status:
    availableReplicas: 3
    conditions:
    - lastTransitionTime: "2025-11-13T08:21:30Z"
      lastUpdateTime: "2025-11-13T08:21:36Z"
      message: ReplicaSet "csi-provisioner-57f9d44448" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-10T22:39:34Z"
      lastUpdateTime: "2025-12-10T22:39:34Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 3
    replicas: 3
    updatedReplicas: 3
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      driver.longhorn.io/git-commit: 29b7fda2692c8df5b1aa18c477f77863c7acc1e7
      driver.longhorn.io/version: v1.10.1
      longhorn.io/last-applied-tolerations: '[]'
    creationTimestamp: "2025-11-13T08:21:32Z"
    generation: 1
    labels:
      app: csi-resizer
      longhorn.io/managed-by: longhorn-manager
    name: csi-resizer
    namespace: longhorn-system
    resourceVersion: "54064840"
    uid: 6a127a39-b7be-4317-b866-fadd47c7a90d
  spec:
    progressDeadlineSeconds: 600
    replicas: 3
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: csi-resizer
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app: csi-resizer
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: app
                    operator: In
                    values:
                    - csi-resizer
                topologyKey: kubernetes.io/hostname
              weight: 1
        containers:
        - args:
          - --v=2
          - --csi-address=$(ADDRESS)
          - --timeout=1m50s
          - --leader-election
          - --leader-election-namespace=$(POD_NAMESPACE)
          - --leader-election-namespace=$(POD_NAMESPACE)
          - --kube-api-qps=50
          - --kube-api-burst=100
          - --http-endpoint=:8000
          - --handle-volume-inuse-error=false
          - --feature-gates=RecoverVolumeExpansionFailure=false
          env:
          - name: ADDRESS
            value: /csi/csi.sock
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          image: longhornio/csi-resizer:v1.14.0-20251030
          imagePullPolicy: IfNotPresent
          name: csi-resizer
          ports:
          - containerPort: 8000
            name: csi-resizer
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /csi/
            name: socket-dir
        dnsPolicy: ClusterFirst
        priorityClassName: longhorn-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: longhorn-service-account
        serviceAccountName: longhorn-service-account
        terminationGracePeriodSeconds: 30
        volumes:
        - hostPath:
            path: /var/lib/kubelet/plugins/driver.longhorn.io
            type: DirectoryOrCreate
          name: socket-dir
  status:
    availableReplicas: 3
    conditions:
    - lastTransitionTime: "2025-11-13T08:21:32Z"
      lastUpdateTime: "2025-11-13T08:21:38Z"
      message: ReplicaSet "csi-resizer-547f8b9dc8" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-10T22:39:20Z"
      lastUpdateTime: "2025-12-10T22:39:20Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 3
    replicas: 3
    updatedReplicas: 3
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      driver.longhorn.io/git-commit: 29b7fda2692c8df5b1aa18c477f77863c7acc1e7
      driver.longhorn.io/version: v1.10.1
      longhorn.io/last-applied-tolerations: '[]'
    creationTimestamp: "2025-11-13T08:21:35Z"
    generation: 1
    labels:
      app: csi-snapshotter
      longhorn.io/managed-by: longhorn-manager
    name: csi-snapshotter
    namespace: longhorn-system
    resourceVersion: "54430495"
    uid: 7af9e402-3db2-4709-9756-866f1f69e09b
  spec:
    progressDeadlineSeconds: 600
    replicas: 3
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: csi-snapshotter
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app: csi-snapshotter
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: app
                    operator: In
                    values:
                    - csi-snapshotter
                topologyKey: kubernetes.io/hostname
              weight: 1
        containers:
        - args:
          - --v=2
          - --csi-address=$(ADDRESS)
          - --timeout=1m50s
          - --leader-election
          - --leader-election-namespace=$(POD_NAMESPACE)
          - --kube-api-qps=50
          - --kube-api-burst=100
          - --http-endpoint=:8000
          env:
          - name: ADDRESS
            value: /csi/csi.sock
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          image: longhornio/csi-snapshotter:v8.4.0-20251030
          imagePullPolicy: IfNotPresent
          name: csi-snapshotter
          ports:
          - containerPort: 8000
            name: csi-snapshotter
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /csi/
            name: socket-dir
        dnsPolicy: ClusterFirst
        priorityClassName: longhorn-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: longhorn-service-account
        serviceAccountName: longhorn-service-account
        terminationGracePeriodSeconds: 30
        volumes:
        - hostPath:
            path: /var/lib/kubelet/plugins/driver.longhorn.io
            type: DirectoryOrCreate
          name: socket-dir
  status:
    availableReplicas: 3
    conditions:
    - lastTransitionTime: "2025-11-13T08:21:35Z"
      lastUpdateTime: "2025-11-13T08:21:40Z"
      message: ReplicaSet "csi-snapshotter-8558df8679" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-12T05:51:18Z"
      lastUpdateTime: "2025-12-12T05:51:18Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 3
    replicas: 3
    updatedReplicas: 3
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "5"
      meta.helm.sh/release-name: longhorn
      meta.helm.sh/release-namespace: longhorn-system
    creationTimestamp: "2025-11-23T11:36:00Z"
    generation: 10
    labels:
      app.kubernetes.io/instance: longhorn
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: longhorn
      app.kubernetes.io/version: v1.10.1
      helm.sh/chart: longhorn-1.10.1
    name: longhorn-driver-deployer
    namespace: longhorn-system
    resourceVersion: "54065480"
    uid: bda86572-71bf-4ae7-90e3-b90599a55f27
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: longhorn-driver-deployer
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app: longhorn-driver-deployer
          app.kubernetes.io/instance: longhorn
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: longhorn
          app.kubernetes.io/version: v1.10.1
          helm.sh/chart: longhorn-1.10.1
      spec:
        containers:
        - command:
          - longhorn-manager
          - -d
          - deploy-driver
          - --manager-image
          - longhornio/longhorn-manager:v1.10.1
          - --manager-url
          - http://longhorn-backend:9500/v1
          env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: SERVICE_ACCOUNT
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.serviceAccountName
          - name: CSI_ATTACHER_IMAGE
            value: longhornio/csi-attacher:v4.10.0-20251030
          - name: CSI_PROVISIONER_IMAGE
            value: longhornio/csi-provisioner:v5.3.0-20251030
          - name: CSI_NODE_DRIVER_REGISTRAR_IMAGE
            value: longhornio/csi-node-driver-registrar:v2.15.0-20251030
          - name: CSI_RESIZER_IMAGE
            value: longhornio/csi-resizer:v1.14.0-20251030
          - name: CSI_SNAPSHOTTER_IMAGE
            value: longhornio/csi-snapshotter:v8.4.0-20251030
          - name: CSI_LIVENESS_PROBE_IMAGE
            value: longhornio/livenessprobe:v2.17.0-20251030
          image: longhornio/longhorn-manager:v1.10.1
          imagePullPolicy: IfNotPresent
          name: longhorn-driver-deployer
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        initContainers:
        - command:
          - sh
          - -c
          - while [ $(curl -m 1 -s -o /dev/null -w "%{http_code}" http://longhorn-backend:9500/v1)
            != "200" ]; do echo waiting; sleep 2; done
          image: longhornio/longhorn-manager:v1.10.1
          imagePullPolicy: IfNotPresent
          name: wait-longhorn-manager
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        priorityClassName: longhorn-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          runAsUser: 0
        serviceAccount: longhorn-service-account
        serviceAccountName: longhorn-service-account
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-11-23T11:36:00Z"
      lastUpdateTime: "2025-11-23T12:54:06Z"
      message: ReplicaSet "longhorn-driver-deployer-c4765874d" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-10T22:39:38Z"
      lastUpdateTime: "2025-12-10T22:39:38Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 10
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "5"
      meta.helm.sh/release-name: longhorn
      meta.helm.sh/release-namespace: longhorn-system
    creationTimestamp: "2025-11-23T11:36:00Z"
    generation: 10
    labels:
      app: longhorn-ui
      app.kubernetes.io/instance: longhorn
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: longhorn
      app.kubernetes.io/version: v1.10.1
      helm.sh/chart: longhorn-1.10.1
    name: longhorn-ui
    namespace: longhorn-system
    resourceVersion: "52386408"
    uid: 250bd3a9-6785-4e8f-8771-b4eab1abfdbd
  spec:
    progressDeadlineSeconds: 600
    replicas: 2
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: longhorn-ui
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app: longhorn-ui
          app.kubernetes.io/instance: longhorn
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: longhorn
          app.kubernetes.io/version: v1.10.1
          helm.sh/chart: longhorn-1.10.1
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: app
                    operator: In
                    values:
                    - longhorn-ui
                topologyKey: kubernetes.io/hostname
              weight: 1
        containers:
        - env:
          - name: LONGHORN_MANAGER_IP
            value: http://longhorn-backend:9500
          - name: LONGHORN_UI_PORT
            value: "8000"
          image: longhornio/longhorn-ui:v1.10.1
          imagePullPolicy: IfNotPresent
          name: longhorn-ui
          ports:
          - containerPort: 8000
            name: http
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/cache/nginx/
            name: nginx-cache
          - mountPath: /var/config/nginx/
            name: nginx-config
          - mountPath: /var/run/
            name: var-run
        dnsPolicy: ClusterFirst
        priorityClassName: longhorn-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: longhorn-ui-service-account
        serviceAccountName: longhorn-ui-service-account
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        volumes:
        - emptyDir: {}
          name: nginx-cache
        - emptyDir: {}
          name: nginx-config
        - emptyDir: {}
          name: var-run
  status:
    availableReplicas: 2
    conditions:
    - lastTransitionTime: "2025-11-23T11:36:03Z"
      lastUpdateTime: "2025-11-23T11:36:03Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-11-23T11:36:00Z"
      lastUpdateTime: "2025-11-23T12:54:04Z"
      message: ReplicaSet "longhorn-ui-59b6bd9bbf" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 10
    readyReplicas: 2
    replicas: 2
    updatedReplicas: 2
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "6"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app.kubernetes.io/instance":"flaresolverr"},"name":"flaresolverr","namespace":"media"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"flaresolverr"}},"template":{"metadata":{"labels":{"app":"flaresolverr"}},"spec":{"containers":[{"env":[{"name":"LOG_LEVEL","value":"info"},{"name":"LOG_HTML","value":"false"},{"name":"TZ","value":"Europe/Madrid"},{"name":"CAPTCHA_SOLVER","value":"none"}],"image":"ghcr.io/flaresolverr/flaresolverr:v3.4.6","livenessProbe":{"failureThreshold":3,"httpGet":{"path":"/","port":8191},"initialDelaySeconds":30,"periodSeconds":30,"timeoutSeconds":5},"name":"flaresolverr","ports":[{"containerPort":8191}],"readinessProbe":{"failureThreshold":3,"httpGet":{"path":"/","port":8191},"initialDelaySeconds":15,"periodSeconds":10,"timeoutSeconds":5},"resources":{"limits":{"cpu":"1000m","memory":"1Gi"},"requests":{"cpu":"100m","memory":"256Mi"}}}]}}}}
    creationTimestamp: "2025-12-10T08:31:52Z"
    generation: 6
    labels:
      app.kubernetes.io/instance: flaresolverr
    name: flaresolverr
    namespace: media
    resourceVersion: "54066502"
    uid: ae72ee2f-2a2a-4c61-a9d4-7c01cddcabfa
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: flaresolverr
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-10T17:54:46+01:00"
        labels:
          app: flaresolverr
      spec:
        containers:
        - env:
          - name: LOG_LEVEL
            value: info
          - name: LOG_HTML
            value: "false"
          - name: TZ
            value: Europe/Madrid
          - name: CAPTCHA_SOLVER
            value: none
          image: ghcr.io/flaresolverr/flaresolverr:v3.4.6
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 8191
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 5
          name: flaresolverr
          ports:
          - containerPort: 8191
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 8191
              scheme: HTTP
            initialDelaySeconds: 15
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          resources:
            limits:
              cpu: "1"
              memory: 1Gi
            requests:
              cpu: 100m
              memory: 256Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-12-10T08:31:52Z"
      lastUpdateTime: "2025-12-10T16:55:08Z"
      message: ReplicaSet "flaresolverr-dc8bc754" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-10T22:39:53Z"
      lastUpdateTime: "2025-12-10T22:39:53Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 6
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "8"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app.kubernetes.io/instance":"jackett"},"name":"jackett","namespace":"media"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"jackett"}},"template":{"metadata":{"labels":{"app":"jackett"}},"spec":{"containers":[{"env":[{"name":"PUID","value":"65534"},{"name":"PGID","value":"65534"},{"name":"HTTP_PROXY","value":"http://qbitt.media.svc.cluster.local:8888"},{"name":"HTTPS_PROXY","value":"http://qbitt.media.svc.cluster.local:8888"},{"name":"NO_PROXY","value":"localhost,127.0.0.1,.cluster.local"}],"image":"linuxserver/jackett:0.24.360","livenessProbe":{"failureThreshold":3,"initialDelaySeconds":60,"periodSeconds":30,"tcpSocket":{"port":9117},"timeoutSeconds":5},"name":"jackett","ports":[{"containerPort":9117}],"readinessProbe":{"failureThreshold":3,"initialDelaySeconds":30,"periodSeconds":10,"tcpSocket":{"port":9117},"timeoutSeconds":5},"volumeMounts":[{"mountPath":"/config","name":"config"}]},{"env":[{"name":"LOG_LEVEL","value":"info"},{"name":"LOG_HTML","value":"false"},{"name":"TZ","value":"Europe/Madrid"},{"name":"CAPTCHA_SOLVER","value":"none"}],"image":"ghcr.io/flaresolverr/flaresolverr:v3.3.21","name":"flaresolverr","ports":[{"containerPort":8191,"name":"flaresolverr"}],"resources":{"limits":{"cpu":"1000m","memory":"1Gi"},"requests":{"cpu":"100m","memory":"256Mi"}}}],"volumes":[{"name":"config","persistentVolumeClaim":{"claimName":"jackett"}}]}}}}
    creationTimestamp: "2025-10-26T10:39:50Z"
    generation: 21
    labels:
      app.kubernetes.io/instance: jackett
    name: jackett
    namespace: media
    resourceVersion: "54196790"
    uid: 4b5d1c5d-3083-4cf7-acf2-5ed792fdc40f
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: jackett
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-11T10:28:50+01:00"
        labels:
          app: jackett
      spec:
        containers:
        - env:
          - name: PUID
            value: "65534"
          - name: PGID
            value: "65534"
          - name: HTTP_PROXY
            value: http://qbitt.media.svc.cluster.local:8888
          - name: HTTPS_PROXY
            value: http://qbitt.media.svc.cluster.local:8888
          - name: NO_PROXY
            value: localhost,127.0.0.1,.cluster.local
          image: linuxserver/jackett:0.24.360
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 60
            periodSeconds: 30
            successThreshold: 1
            tcpSocket:
              port: 9117
            timeoutSeconds: 5
          name: jackett
          ports:
          - containerPort: 9117
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: 9117
            timeoutSeconds: 5
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /config
            name: config
        - env:
          - name: LOG_LEVEL
            value: info
          - name: LOG_HTML
            value: "false"
          - name: TZ
            value: Europe/Madrid
          - name: CAPTCHA_SOLVER
            value: none
          image: ghcr.io/flaresolverr/flaresolverr:v3.3.21
          imagePullPolicy: IfNotPresent
          name: flaresolverr
          ports:
          - containerPort: 8191
            name: flaresolverr
            protocol: TCP
          resources:
            limits:
              cpu: "1"
              memory: 1Gi
            requests:
              cpu: 100m
              memory: 256Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: config
          persistentVolumeClaim:
            claimName: jackett
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-12-10T22:41:30Z"
      lastUpdateTime: "2025-12-10T22:41:30Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-10-26T10:39:50Z"
      lastUpdateTime: "2025-12-11T09:29:25Z"
      message: ReplicaSet "jackett-644f4c756b" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 21
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "2"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app":"metallb","component":"controller"},"name":"controller","namespace":"metallb-system"},"spec":{"revisionHistoryLimit":3,"selector":{"matchLabels":{"app":"metallb","component":"controller"}},"template":{"metadata":{"annotations":{"prometheus.io/port":"7472","prometheus.io/scrape":"true"},"labels":{"app":"metallb","component":"controller"}},"spec":{"containers":[{"args":["--port=7472","--log-level=info","--tls-min-version=VersionTLS12"],"env":[{"name":"METALLB_ML_SECRET_NAME","value":"memberlist"},{"name":"METALLB_DEPLOYMENT","value":"controller"}],"image":"quay.io/metallb/controller:v0.14.8","livenessProbe":{"failureThreshold":3,"httpGet":{"path":"/metrics","port":"monitoring"},"initialDelaySeconds":10,"periodSeconds":10,"successThreshold":1,"timeoutSeconds":1},"name":"controller","ports":[{"containerPort":7472,"name":"monitoring"},{"containerPort":9443,"name":"webhook-server","protocol":"TCP"}],"readinessProbe":{"failureThreshold":3,"httpGet":{"path":"/metrics","port":"monitoring"},"initialDelaySeconds":10,"periodSeconds":10,"successThreshold":1,"timeoutSeconds":1},"securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["all"]},"readOnlyRootFilesystem":true},"volumeMounts":[{"mountPath":"/tmp/k8s-webhook-server/serving-certs","name":"cert","readOnly":true}]}],"nodeSelector":{"kubernetes.io/os":"linux"},"securityContext":{"fsGroup":65534,"runAsNonRoot":true,"runAsUser":65534},"serviceAccountName":"controller","terminationGracePeriodSeconds":0,"volumes":[{"name":"cert","secret":{"defaultMode":420,"secretName":"metallb-webhook-cert"}}]}}}}
    creationTimestamp: "2024-12-21T11:37:33Z"
    generation: 2
    labels:
      app: metallb
      component: controller
    name: controller
    namespace: metallb-system
    resourceVersion: "40548797"
    uid: 6d3d0fe6-0b8c-4bc9-9f06-6b7e187b6b3a
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 3
    selector:
      matchLabels:
        app: metallb
        component: controller
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          prometheus.io/port: "7472"
          prometheus.io/scrape: "true"
        labels:
          app: metallb
          component: controller
      spec:
        containers:
        - args:
          - --port=7472
          - --log-level=info
          - --tls-min-version=VersionTLS12
          env:
          - name: METALLB_ML_SECRET_NAME
            value: memberlist
          - name: METALLB_DEPLOYMENT
            value: controller
          image: quay.io/metallb/controller:v0.14.8
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /metrics
              port: monitoring
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: controller
          ports:
          - containerPort: 7472
            name: monitoring
            protocol: TCP
          - containerPort: 9443
            name: webhook-server
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /metrics
              port: monitoring
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - all
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp/k8s-webhook-server/serving-certs
            name: cert
            readOnly: true
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
        serviceAccount: controller
        serviceAccountName: controller
        terminationGracePeriodSeconds: 0
        volumes:
        - name: cert
          secret:
            defaultMode: 420
            secretName: metallb-webhook-cert
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-12-21T11:37:33Z"
      lastUpdateTime: "2025-10-21T16:30:52Z"
      message: ReplicaSet "controller-5995677bd5" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-10-21T17:32:53Z"
      lastUpdateTime: "2025-10-21T17:32:53Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 2
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2025-10-23T22:00:54Z"
    generation: 6
    labels:
      app: minio
      app.kubernetes.io/instance: minio
      chart: minio-5.4.0
      heritage: Helm
      release: minio
    name: minio
    namespace: minio
    resourceVersion: "54065042"
    uid: e09e9ad9-df33-402c-ac3a-3a665acbd9fa
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: minio
        release: minio
    strategy:
      rollingUpdate:
        maxSurge: 100%
        maxUnavailable: 0
      type: RollingUpdate
    template:
      metadata:
        annotations:
          checksum/config: d7787e9aef31fa7be8453cd19a250082a8f94ea127922a45ee713590591c43c7
          checksum/secrets: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
        labels:
          app: minio
          release: minio
        name: minio
      spec:
        containers:
        - command:
          - /bin/sh
          - -ce
          - /usr/bin/docker-entrypoint.sh minio server /export -S /etc/minio/certs/
            --address :9000 --console-address :9001
          env:
          - name: MINIO_ROOT_USER
            valueFrom:
              secretKeyRef:
                key: rootUser
                name: minio-login
          - name: MINIO_ROOT_PASSWORD
            valueFrom:
              secretKeyRef:
                key: rootPassword
                name: minio-login
          - name: MINIO_PROMETHEUS_AUTH_TYPE
            value: public
          - name: MINIO_CI_CD
            value: "on"
          - name: MINIO_DRIVE_HEALTH_CHECK_INTERVAL
            value: 60s
          - name: MINIO_DRIVE_HEALTH_CHECK_TIMEOUT
            value: 120s
          image: quay.io/minio/minio:RELEASE.2024-12-18T13-15-44Z
          imagePullPolicy: IfNotPresent
          name: minio
          ports:
          - containerPort: 9000
            name: http
            protocol: TCP
          - containerPort: 9001
            name: http-console
            protocol: TCP
          resources:
            limits:
              cpu: "1"
              memory: 4Gi
            requests:
              cpu: 500m
              memory: 2Gi
          securityContext:
            readOnlyRootFilesystem: false
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp/credentials
            name: minio-user
            readOnly: true
          - mountPath: /export
            name: export
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 100
          fsGroupChangePolicy: OnRootMismatch
          runAsGroup: 100
          runAsUser: 65534
        serviceAccount: minio-sa
        serviceAccountName: minio-sa
        terminationGracePeriodSeconds: 30
        volumes:
        - name: export
          persistentVolumeClaim:
            claimName: minio
        - name: minio-user
          secret:
            defaultMode: 420
            secretName: minio-login
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-10-23T22:00:54Z"
      lastUpdateTime: "2025-10-23T22:01:01Z"
      message: ReplicaSet "minio-786c6ff4f7" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-10T22:39:33Z"
      lastUpdateTime: "2025-12-10T22:39:33Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 6
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "56"
    creationTimestamp: "2025-11-23T20:52:09Z"
    generation: 56
    labels:
      app.kubernetes.io/instance: monitoring
      app.kubernetes.io/name: grafana
      app.kubernetes.io/version: 12.2.1
      helm.sh/chart: grafana-10.1.4
    name: monitoring-grafana
    namespace: monitoring
    resourceVersion: "54068683"
    uid: 983005d7-793d-4d7b-8c51-9c32810057d7
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/name: grafana
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          checksum/config: 0e9cbd0ea8e24e32f7dfca5bab17a2ba05652642f0a09a4882833ae88e4cc4a3
          checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
          checksum/secret: d484169b028b5081d7ad35eff203f36c3bc6b5a1a27ddca86e14251e0192a68d
          kubectl.kubernetes.io/default-container: grafana
        labels:
          app.kubernetes.io/instance: monitoring
          app.kubernetes.io/name: grafana
          app.kubernetes.io/version: 12.2.1
          helm.sh/chart: grafana-10.1.4
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_dashboard
          - name: LABEL_VALUE
            value: "1"
          - name: FOLDER
            value: /tmp/dashboards
          - name: RESOURCE
            value: both
          - name: NAMESPACE
            value: ALL
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: monitoring-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: monitoring-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/dashboards/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.30.10
          imagePullPolicy: IfNotPresent
          name: grafana-sc-dashboard
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_datasource
          - name: LABEL_VALUE
            value: "1"
          - name: FOLDER
            value: /etc/grafana/provisioning/datasources
          - name: RESOURCE
            value: both
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: monitoring-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: monitoring-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/datasources/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.30.10
          imagePullPolicy: IfNotPresent
          name: grafana-sc-datasources
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        - env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: GF_SECURITY_ADMIN_USER
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: monitoring-grafana
          - name: GF_SECURITY_ADMIN_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: monitoring-grafana
          - name: GF_PATHS_DATA
            value: /var/lib/grafana/
          - name: GF_PATHS_LOGS
            value: /var/log/grafana
          - name: GF_PATHS_PLUGINS
            value: /var/lib/grafana/plugins
          - name: GF_PATHS_PROVISIONING
            value: /etc/grafana/provisioning
          image: docker.io/grafana/grafana:12.2.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 30
          name: grafana
          ports:
          - containerPort: 3000
            name: grafana
            protocol: TCP
          - containerPort: 9094
            name: gossip-tcp
            protocol: TCP
          - containerPort: 9094
            name: gossip-udp
            protocol: UDP
          - containerPort: 6060
            name: profiling
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/grafana.ini
            name: config
            subPath: grafana.ini
          - mountPath: /var/lib/grafana
            name: storage
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
          - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
            name: sc-dashboard-provider
            subPath: provider.yaml
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        initContainers:
        - command:
          - chown
          - -R
          - 472:472
          - /var/lib/grafana
          image: docker.io/library/busybox:1.31.1
          imagePullPolicy: IfNotPresent
          name: init-chown-data
          resources: {}
          securityContext:
            capabilities:
              add:
              - CHOWN
              drop:
              - ALL
            readOnlyRootFilesystem: false
            runAsNonRoot: false
            runAsUser: 0
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/grafana
            name: storage
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 472
          runAsGroup: 472
          runAsNonRoot: true
          runAsUser: 472
        serviceAccount: monitoring-grafana
        serviceAccountName: monitoring-grafana
        shareProcessNamespace: false
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: monitoring-grafana
          name: config
        - name: storage
          persistentVolumeClaim:
            claimName: monitoring-grafana
        - emptyDir: {}
          name: sc-dashboard-volume
        - configMap:
            defaultMode: 420
            name: monitoring-grafana-config-dashboards
          name: sc-dashboard-provider
        - emptyDir: {}
          name: sc-datasources-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-11-23T20:52:09Z"
      lastUpdateTime: "2025-12-05T12:54:54Z"
      message: ReplicaSet "monitoring-grafana-5449cff849" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-10T22:42:00Z"
      lastUpdateTime: "2025-12-10T22:42:00Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 56
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "3"
    creationTimestamp: "2025-11-23T20:52:09Z"
    generation: 3
    labels:
      app: kube-prometheus-stack-operator
      app.kubernetes.io/component: prometheus-operator
      app.kubernetes.io/instance: monitoring
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 79.4.1
      chart: kube-prometheus-stack-79.4.1
      heritage: Helm
      release: monitoring
    name: monitoring-kube-prometheus-operator
    namespace: monitoring
    resourceVersion: "49178371"
    uid: ec661fc7-069a-43f8-a9f8-582b5b272b35
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: kube-prometheus-stack-operator
        release: monitoring
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app: kube-prometheus-stack-operator
          app.kubernetes.io/component: prometheus-operator
          app.kubernetes.io/instance: monitoring
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
          app.kubernetes.io/part-of: kube-prometheus-stack
          app.kubernetes.io/version: 79.4.1
          chart: kube-prometheus-stack-79.4.1
          heritage: Helm
          release: monitoring
      spec:
        automountServiceAccountToken: true
        containers:
        - args:
          - --kubelet-service=kube-system/monitoring-kube-prometheus-kubelet
          - --kubelet-endpoints=true
          - --kubelet-endpointslice=false
          - --localhost=127.0.0.1
          - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.86.2
          - --config-reloader-cpu-request=0
          - --config-reloader-cpu-limit=0
          - --config-reloader-memory-request=0
          - --config-reloader-memory-limit=0
          - --thanos-default-base-image=quay.io/thanos/thanos:v0.40.1
          - --secret-field-selector=type!=kubernetes.io/dockercfg,type!=kubernetes.io/service-account-token,type!=helm.sh/release.v1
          - --web.enable-tls=true
          - --web.cert-file=/cert/cert
          - --web.key-file=/cert/key
          - --web.listen-address=:10250
          - --web.tls-min-version=VersionTLS13
          env:
          - name: GOGC
            value: "30"
          image: quay.io/prometheus-operator/prometheus-operator:v0.86.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: https
              scheme: HTTPS
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: kube-prometheus-stack
          ports:
          - containerPort: 10250
            name: https
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: https
              scheme: HTTPS
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /cert
            name: tls-secret
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: monitoring-kube-prometheus-operator
        serviceAccountName: monitoring-kube-prometheus-operator
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        volumes:
        - name: tls-secret
          secret:
            defaultMode: 420
            secretName: monitoring-kube-prometheus-admission
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-11-23T20:58:00Z"
      lastUpdateTime: "2025-11-23T20:58:00Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-11-23T20:52:09Z"
      lastUpdateTime: "2025-11-23T21:11:16Z"
      message: ReplicaSet "monitoring-kube-prometheus-operator-8455c9fbd" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 3
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2025-11-23T20:52:09Z"
    generation: 1
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: monitoring
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-state-metrics
      app.kubernetes.io/version: 2.17.0
      helm.sh/chart: kube-state-metrics-6.4.1
      release: monitoring
    name: monitoring-kube-state-metrics
    namespace: monitoring
    resourceVersion: "54066368"
    uid: ef55ac9b-6f2f-4d9b-9432-e12961c638a2
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/name: kube-state-metrics
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app.kubernetes.io/component: metrics
          app.kubernetes.io/instance: monitoring
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: kube-state-metrics
          app.kubernetes.io/part-of: kube-state-metrics
          app.kubernetes.io/version: 2.17.0
          helm.sh/chart: kube-state-metrics-6.4.1
          release: monitoring
      spec:
        automountServiceAccountToken: true
        containers:
        - args:
          - --port=8080
          - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,leases,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
          image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.17.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /livez
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: kube-state-metrics
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: 8081
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: monitoring-kube-state-metrics
        serviceAccountName: monitoring-kube-state-metrics
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-11-23T20:52:09Z"
      lastUpdateTime: "2025-11-23T20:52:21Z"
      message: ReplicaSet "monitoring-kube-state-metrics-5459bf8fdf" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-10T22:39:48Z"
      lastUpdateTime: "2025-12-10T22:39:48Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "2"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app":"mosquitto"},"name":"mosquitto","namespace":"mosquitto"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"mosquitto"}},"template":{"metadata":{"labels":{"app":"mosquitto"}},"spec":{"containers":[{"image":"eclipse-mosquitto:2.0.20","livenessProbe":{"initialDelaySeconds":10,"periodSeconds":10,"tcpSocket":{"port":1883}},"name":"mosquitto","ports":[{"containerPort":1883,"name":"mqtt","protocol":"TCP"}],"readinessProbe":{"initialDelaySeconds":5,"periodSeconds":5,"tcpSocket":{"port":1883}},"resources":{"limits":{"cpu":"200m","memory":"128Mi"},"requests":{"cpu":"50m","memory":"64Mi"}},"volumeMounts":[{"mountPath":"/mosquitto/config","name":"config"},{"mountPath":"/mosquitto/data","name":"data"}]}],"volumes":[{"configMap":{"name":"mosquitto-config"},"name":"config"},{"emptyDir":{},"name":"data"}]}}}}
    creationTimestamp: "2025-11-18T17:41:17Z"
    generation: 2
    labels:
      app: mosquitto
    name: mosquitto
    namespace: mosquitto
    resourceVersion: "54065743"
    uid: 60573b67-d6a9-4f72-abf2-658e9e45e75b
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: mosquitto
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app: mosquitto
      spec:
        containers:
        - image: eclipse-mosquitto:2.0.20
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: 1883
            timeoutSeconds: 1
          name: mosquitto
          ports:
          - containerPort: 1883
            name: mqtt
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 5
            periodSeconds: 5
            successThreshold: 1
            tcpSocket:
              port: 1883
            timeoutSeconds: 1
          resources:
            limits:
              cpu: 200m
              memory: 128Mi
            requests:
              cpu: 50m
              memory: 64Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /mosquitto/config
            name: config
          - mountPath: /mosquitto/data
            name: data
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: mosquitto-config
          name: config
        - emptyDir: {}
          name: data
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-11-18T17:41:17Z"
      lastUpdateTime: "2025-11-18T17:42:33Z"
      message: ReplicaSet "mosquitto-69fbc9fd6c" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-10T22:39:40Z"
      lastUpdateTime: "2025-12-10T22:39:40Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 2
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      checksum/configs: 6de56b41c1bfc4cb050b33b77ef600dc3540d154790fa6d8edeac75cb7c2ba99
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2025-10-23T11:26:48Z"
    generation: 17
    labels:
      app.kubernetes.io/instance: opencost
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: opencost
      app.kubernetes.io/part-of: opencost
      app.kubernetes.io/version: 1.117.6
      helm.sh/chart: opencost-2.3.2
    name: opencost
    namespace: opencost
    resourceVersion: "54069194"
    uid: d898c8b5-2824-4db2-a235-6e7ffbe792bf
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: opencost
        app.kubernetes.io/name: opencost
    strategy:
      rollingUpdate:
        maxSurge: 1
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        labels:
          app.kubernetes.io/instance: opencost
          app.kubernetes.io/name: opencost
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: LOG_LEVEL
            value: info
          - name: CUSTOM_COST_ENABLED
            value: "false"
          - name: INSTALL_NAMESPACE
            value: opencost
          - name: PROMETHEUS_QUERY_RESOLUTION_SECONDS
            value: "300"
          - name: API_PORT
            value: "9003"
          - name: PROMETHEUS_SERVER_ENDPOINT
            value: http://monitoring-kube-prometheus-prometheus.monitoring.svc.cluster.local:9090
          - name: INSECURE_SKIP_VERIFY
            value: "false"
          - name: CLUSTER_ID
            value: homelab-cluster
          - name: PV_MOUNT_PATH
            value: /mnt/export
          - name: RESOLUTION_1D_RETENTION
            value: "30"
          - name: RESOLUTION_1H_RETENTION
            value: "49"
          - name: CLOUD_COST_ENABLED
            value: "false"
          - name: CLOUD_COST_MONTH_TO_DATE_INTERVAL
            value: "6"
          - name: CLOUD_COST_REFRESH_RATE_HOURS
            value: "6"
          - name: CLOUD_COST_QUERY_WINDOW_DAYS
            value: "7"
          - name: CLOUD_COST_RUN_WINDOW_DAYS
            value: "3"
          - name: EMIT_KSM_V1_METRICS
            value: "false"
          - name: EMIT_KSM_V1_METRICS_ONLY
            value: "false"
          image: ghcr.io/opencost/opencost:1.117.6@sha256:6f1a0e6fe21559a77051e7b7f9e4ac6bc80277131492ae084e8365ada805af91
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 9003
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 20
            successThreshold: 1
            timeoutSeconds: 1
          name: opencost
          ports:
          - containerPort: 9003
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 9003
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              memory: 1Gi
            requests:
              cpu: 10m
              memory: 55Mi
          startupProbe:
            failureThreshold: 30
            httpGet:
              path: /healthz
              port: 9003
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /mnt/export
            name: opencost-export
        - env:
          - name: API_PORT
            value: "9003"
          - name: UI_PORT
            value: "9090"
          image: ghcr.io/opencost/opencost-ui:1.117.6@sha256:fd26f004b2b2565e22240fc2a9f6adb078fdb4de3fc1a1b16c611a3c3b80683e
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 9090
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: opencost-ui
          ports:
          - containerPort: 9090
            name: http-ui
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 9090
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              memory: 1Gi
            requests:
              cpu: 10m
              memory: 55Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/nginx/conf.d/default.nginx.conf
            name: opencost-ui-nginx-config-volume
            subPath: default.nginx.conf
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: opencost
        serviceAccountName: opencost
        terminationGracePeriodSeconds: 30
        volumes:
        - name: opencost-export
          persistentVolumeClaim:
            claimName: opencost-pvc
        - configMap:
            defaultMode: 420
            items:
            - key: nginx.conf
              path: default.nginx.conf
            name: opencost-ui-nginx-config
          name: opencost-ui-nginx-config-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-10-23T11:26:48Z"
      lastUpdateTime: "2025-10-23T11:26:48Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-10-23T11:26:48Z"
      lastUpdateTime: "2025-10-23T11:27:50Z"
      message: ReplicaSet "opencost-55b8bd4f9c" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 17
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "16"
    creationTimestamp: "2025-10-08T16:01:55Z"
    generation: 22
    labels:
      app: roomio-frontend
      app.kubernetes.io/instance: roomio-dev
      app.kubernetes.io/managed-by: kustomize
      app.kubernetes.io/name: roomio-frontend
      app.kubernetes.io/part-of: roomio
      environment: development
    name: dev-roomio-frontend
    namespace: roomio-dev
    resourceVersion: "49185775"
    uid: b0707b06-a83a-4024-8fc8-0337e3ade015
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 3
    selector:
      matchLabels:
        app: roomio-frontend
        app.kubernetes.io/instance: roomio-dev
        app.kubernetes.io/managed-by: kustomize
        app.kubernetes.io/part-of: roomio
        environment: development
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app: roomio-frontend
          app.kubernetes.io/instance: roomio-dev
          app.kubernetes.io/managed-by: kustomize
          app.kubernetes.io/name: roomio-frontend
          app.kubernetes.io/part-of: roomio
          environment: development
      spec:
        containers:
        - env:
          - name: NODE_ENV
            value: development
          - name: ENVIRONMENT
            value: dev
          image: ghcr.io/pablodelarco/roomio:sha-52cdc8c
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: frontend
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          resources:
            limits:
              cpu: 100m
              memory: 128Mi
            requests:
              cpu: 25m
              memory: 32Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/hostname: beelink
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 101
          runAsNonRoot: true
          runAsUser: 101
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-10-15T12:57:26Z"
      lastUpdateTime: "2025-10-15T12:57:26Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-10-08T16:01:55Z"
      lastUpdateTime: "2025-11-12T14:54:44Z"
      message: ReplicaSet "dev-roomio-frontend-7b4f88bb75" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 22
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "18"
    creationTimestamp: "2025-10-08T15:32:48Z"
    generation: 21
    labels:
      app: roomio-frontend
      app.kubernetes.io/instance: roomio-prod
      app.kubernetes.io/managed-by: kustomize
      app.kubernetes.io/name: roomio-frontend
      app.kubernetes.io/part-of: roomio
      environment: production
    name: prod-roomio-frontend
    namespace: roomio-prod
    resourceVersion: "49185819"
    uid: 3969c3a2-770c-4b9e-a9e2-9e89aa2d2421
  spec:
    progressDeadlineSeconds: 600
    replicas: 3
    revisionHistoryLimit: 3
    selector:
      matchLabels:
        app: roomio-frontend
        app.kubernetes.io/instance: roomio-prod
        app.kubernetes.io/managed-by: kustomize
        app.kubernetes.io/part-of: roomio
        environment: production
    strategy:
      rollingUpdate:
        maxSurge: 1
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-10-19T01:24:14+02:00"
        labels:
          app: roomio-frontend
          app.kubernetes.io/instance: roomio-prod
          app.kubernetes.io/managed-by: kustomize
          app.kubernetes.io/name: roomio-frontend
          app.kubernetes.io/part-of: roomio
          environment: production
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: app
                    operator: In
                    values:
                    - roomio-frontend
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - env:
          - name: NODE_ENV
            value: production
          - name: ENVIRONMENT
            value: production
          image: ghcr.io/pablodelarco/roomio:sha-c8642e8
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: frontend
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 100m
              memory: 128Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/hostname: beelink
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 101
          runAsNonRoot: true
          runAsUser: 101
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
  status:
    availableReplicas: 3
    conditions:
    - lastTransitionTime: "2025-10-15T12:57:28Z"
      lastUpdateTime: "2025-10-15T12:57:28Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-10-08T21:32:54Z"
      lastUpdateTime: "2025-10-18T23:24:31Z"
      message: ReplicaSet "prod-roomio-frontend-747f75bc4d" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 21
    readyReplicas: 3
    replicas: 3
    updatedReplicas: 3
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "12"
    creationTimestamp: "2025-10-08T16:02:04Z"
    generation: 16
    labels:
      app: roomio-frontend
      app.kubernetes.io/instance: roomio-staging
      app.kubernetes.io/managed-by: kustomize
      app.kubernetes.io/name: roomio-frontend
      app.kubernetes.io/part-of: roomio
      environment: staging
    name: staging-roomio-frontend
    namespace: roomio-staging
    resourceVersion: "49185845"
    uid: 2db2371c-df6a-4d0b-91bb-cc23b15bc091
  spec:
    progressDeadlineSeconds: 600
    replicas: 2
    revisionHistoryLimit: 3
    selector:
      matchLabels:
        app: roomio-frontend
        app.kubernetes.io/instance: roomio-staging
        app.kubernetes.io/managed-by: kustomize
        app.kubernetes.io/part-of: roomio
        environment: staging
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        labels:
          app: roomio-frontend
          app.kubernetes.io/instance: roomio-staging
          app.kubernetes.io/managed-by: kustomize
          app.kubernetes.io/name: roomio-frontend
          app.kubernetes.io/part-of: roomio
          environment: staging
      spec:
        containers:
        - env:
          - name: NODE_ENV
            value: production
          - name: ENVIRONMENT
            value: staging
          image: ghcr.io/pablodelarco/roomio:sha-b4f059d
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: frontend
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          resources:
            limits:
              cpu: 200m
              memory: 256Mi
            requests:
              cpu: 50m
              memory: 64Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/hostname: beelink
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 101
          runAsNonRoot: true
          runAsUser: 101
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
  status:
    availableReplicas: 2
    conditions:
    - lastTransitionTime: "2025-10-08T21:33:16Z"
      lastUpdateTime: "2025-10-08T23:38:44Z"
      message: ReplicaSet "staging-roomio-frontend-67fb95d449" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-10-15T12:57:28Z"
      lastUpdateTime: "2025-10-15T12:57:28Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 16
    readyReplicas: 2
    replicas: 2
    updatedReplicas: 2
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "2"
      meta.helm.sh/release-name: tailscale-operator
      meta.helm.sh/release-namespace: tailscale
    creationTimestamp: "2024-12-21T17:08:39Z"
    generation: 6
    labels:
      app.kubernetes.io/instance: tailscale-operator
      app.kubernetes.io/managed-by: Helm
    name: operator
    namespace: tailscale
    resourceVersion: "54065389"
    uid: c9b66686-0326-49f0-9ebe-9f3f8cc84f7c
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: operator
    strategy:
      type: Recreate
    template:
      metadata:
        labels:
          app: operator
      spec:
        containers:
        - env:
          - name: OPERATOR_INITIAL_TAGS
            value: tag:k8s-operator
          - name: OPERATOR_HOSTNAME
            value: tailscale-operator
          - name: OPERATOR_SECRET
            value: operator
          - name: OPERATOR_LOGGING
            value: info
          - name: OPERATOR_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OPERATOR_LOGIN_SERVER
          - name: OPERATOR_INGRESS_CLASS_NAME
            value: tailscale
          - name: CLIENT_ID_FILE
            value: /oauth/client_id
          - name: CLIENT_SECRET_FILE
            value: /oauth/client_secret
          - name: PROXY_IMAGE
            value: tailscale/tailscale:v1.90.8
          - name: PROXY_TAGS
            value: tag:k8s
          - name: APISERVER_PROXY
            value: "false"
          - name: PROXY_FIREWALL_MODE
            value: auto
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          image: tailscale/k8s-operator:v1.90.8
          imagePullPolicy: Always
          name: operator
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /oauth
            name: oauth
            readOnly: true
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: operator
        serviceAccountName: operator
        terminationGracePeriodSeconds: 30
        volumes:
        - name: oauth
          secret:
            defaultMode: 420
            secretName: operator-oauth
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-12-21T17:08:39Z"
      lastUpdateTime: "2025-11-23T11:06:12Z"
      message: ReplicaSet "operator-d4664c7db" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-10T22:39:37Z"
      lastUpdateTime: "2025-12-10T22:39:37Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 6
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "19"
    creationTimestamp: "2024-12-26T21:09:49Z"
    generation: 44
    labels:
      app.kubernetes.io/instance: uptime-kuma
    name: uptime-kuma
    namespace: uptime-kuma
    resourceVersion: "54068944"
    uid: ced35eca-b362-4d99-bd03-65999da634be
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: uptime-kuma
    strategy:
      rollingUpdate:
        maxSurge: 1
        maxUnavailable: 0
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-10-25T21:41:48+02:00"
        labels:
          app: uptime-kuma
      spec:
        containers:
        - env:
          - name: NODE_OPTIONS
            value: --dns-result-order=ipv4first
          image: louislam/uptime-kuma:2.0.2
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 3001
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: uptime-kuma
          ports:
          - containerPort: 3001
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 3001
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/data
            name: data
        dnsConfig:
          options:
          - name: single-request
          - name: ndots
            value: "1"
        dnsPolicy: ClusterFirst
        hostAliases:
        - hostnames:
          - roomiorentals.com
          - dev.roomiorentals.com
          - staging.roomiorentals.com
          ip: 192.168.1.233
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: uptime-kuma-sa
        serviceAccountName: uptime-kuma-sa
        terminationGracePeriodSeconds: 30
        volumes:
        - name: data
          persistentVolumeClaim:
            claimName: uptime-kuma-pvc
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-12-26T21:09:49Z"
      lastUpdateTime: "2025-11-26T16:03:12Z"
      message: ReplicaSet "uptime-kuma-7d659b9594" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-10T22:42:48Z"
      lastUpdateTime: "2025-12-10T22:42:48Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 44
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
kind: List
metadata:
  resourceVersion: ""
